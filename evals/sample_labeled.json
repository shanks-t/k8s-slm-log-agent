[
  {
    "timestamp": 1766954816856.0,
    "timestamp_human": "2025-12-28T14:46:56.856733",
    "namespace": "log-analyzer",
    "pod": "log-analyzer-7669d66676-gvm8p",
    "container": "log-analyzer",
    "node": "node-1",
    "log_line": "{\"timestamp\": \"2025-12-28 20:46:56,856\", \"level\": \"WARNING\", \"logger\": \"opentelemetry.exporter.otlp.proto.grpc.exporter\", \"message\": \"Transient error StatusCode.UNAVAILABLE encountered while exporting traces to tempo.logging.svc.cluster.local:4317, retrying in 0.91s.\"}",
    "detected_severity": "ERROR",
    "signature": "{\"timestamp\": \"<TIMESTAMP>,856\", \"level\": \"WARNING\", \"logger\": \"opentelemetry.exporter.otlp.proto.grpc.exporter\", \"message\": \"Transient error StatusCode.UNAVAILABLE encountered while exporting traces to tempo.logging.svc.cluster.local:<PORT>, retrying in 0.91s.\"}",
    "signature_hash": "562e4ddb",
    "source": "real",
    "root_cause": "tempo_unavailable",
    "severity": "warn",
    "component": "opentelemetry_exporter",
    "summary": "OpenTelemetry exporter cannot reach Tempo service, retrying with backoff",
    "action_needed": "monitor"
  },
  {
    "timestamp": 1766798888497.0,
    "timestamp_human": "2025-12-26T19:28:08.497090",
    "namespace": "log-analyzer",
    "pod": "log-analyzer-66c94c6bcf-lxrbk",
    "container": "log-analyzer",
    "node": "node-1",
    "log_line": "{\"timestamp\": \"2025-12-27 01:28:08,496\", \"level\": \"WARNING\", \"logger\": \"log_analyzer.main\", \"message\": \"No logs found in Loki\", \"trace_id\": \"467cc545a36313aefa609ddf13eceac6\", \"span_id\": \"9708871c3e0eab95\", \"trace_flags\": 1}",
    "detected_severity": "WARN",
    "signature": "{\"timestamp\": \"<TIMESTAMP>,496\", \"level\": \"WARNING\", \"logger\": \"log_analyzer.main\", \"message\": \"No logs found in Loki\", \"trace_id\": \"<HEXID>\", \"span_id\": \"<HEXID>\", \"trace_flags\": 1}",
    "signature_hash": "63dd1e27",
    "source": "real",
    "root_cause": "empty_query_result",
    "severity": "warn",
    "component": "log_analyzer_api",
    "summary": "User query returned no logs from Loki",
    "action_needed": "none"
  },
  {
    "timestamp": 1767055556746.0,
    "timestamp_human": "2025-12-29T18:45:56.746266",
    "namespace": "log-analyzer",
    "pod": "log-analyzer-6579fdbfb-jzlq7",
    "container": "log-analyzer",
    "node": "node-1",
    "log_line": "{\"timestamp\": \"2025-12-30 00:45:56,746\", \"level\": \"WARNING\", \"logger\": \"log_analyzer.main\", \"message\": \"No logs found in Loki\", \"trace_id\": \"e3bd4f2e769e3323730f22505810f0eb\", \"span_id\": \"e220682e015bcfb6\", \"trace_flags\": 1}",
    "detected_severity": "WARN",
    "signature": "{\"timestamp\": \"<TIMESTAMP>,746\", \"level\": \"WARNING\", \"logger\": \"log_analyzer.main\", \"message\": \"No logs found in Loki\", \"trace_id\": \"<HEXID>\", \"span_id\": \"<HEXID>\", \"trace_flags\": 1}",
    "signature_hash": "5e76dd87",
    "source": "real",
    "root_cause": "empty_query_result",
    "severity": "warn",
    "component": "log_analyzer_api",
    "summary": "User query returned no logs from Loki",
    "action_needed": "none"
  },
  {
    "timestamp": 1767057111154.0,
    "timestamp_human": "2025-12-29T19:11:51.154353",
    "namespace": "log-analyzer",
    "pod": "log-analyzer-6579fdbfb-jzlq7",
    "container": "log-analyzer",
    "node": "node-1",
    "log_line": "File \"/usr/local/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app",
    "detected_severity": "ERROR",
    "signature": "File \"/usr/local/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app",
    "signature_hash": "c37472e6",
    "source": "real",
    "root_cause": "exception_stacktrace",
    "severity": "error",
    "component": "log_analyzer_api",
    "summary": "Python exception stacktrace fragment from FastAPI request handler",
    "action_needed": "investigate"
  },
  {
    "timestamp": 1767056653332.0,
    "timestamp_human": "2025-12-29T19:04:13.332244",
    "namespace": "log-analyzer",
    "pod": "log-analyzer-6579fdbfb-jzlq7",
    "container": "log-analyzer",
    "node": "node-1",
    "log_line": "File \"/usr/local/lib/python3.13/site-packages/starlette/middleware/exceptions.py\", line 63, in __call__",
    "detected_severity": "ERROR",
    "signature": "File \"/usr/local/lib/python3.13/site-packages/starlette/middleware/exceptions.py\", line 63, in __call__",
    "signature_hash": "6219d2d9",
    "source": "real",
    "root_cause": "exception_stacktrace",
    "severity": "error",
    "component": "log_analyzer_api",
    "summary": "Python exception stacktrace fragment from FastAPI exception middleware",
    "action_needed": "investigate"
  },
  {
    "timestamp": 1767057238262.0,
    "timestamp_human": "2025-12-29T19:13:58.262613",
    "namespace": "llm",
    "pod": "llama-cpp-968bcbbbd-bjrj5",
    "container": "llama-server",
    "node": "node-2",
    "log_line": "warning: consult docs/build.md for compilation instructions",
    "detected_severity": "WARN",
    "signature": "warning: consult docs/build.md for compilation instructions",
    "signature_hash": "e22fa811",
    "source": "real",
    "root_cause": "build_info_message",
    "severity": "info",
    "component": "llama_cpp",
    "summary": "Informational message about llama.cpp build documentation",
    "action_needed": "none"
  },
  {
    "timestamp": 1767050290439.0,
    "timestamp_human": "2025-12-29T17:18:10.439068",
    "namespace": "llm",
    "pod": "llama-cpp-5644f4579c-qnmvj",
    "container": "llama-server",
    "node": "node-2",
    "log_line": "warning: one possible reason is that llama.cpp was compiled without GPU support",
    "detected_severity": "WARN",
    "signature": "warning: one possible reason is that llama.cpp was compiled without GPU support",
    "signature_hash": "97a76ca0",
    "source": "real",
    "root_cause": "no_gpu_acceleration",
    "severity": "info",
    "component": "llama_cpp",
    "summary": "llama.cpp running without GPU acceleration (expected for CPU-only deployment)",
    "action_needed": "none"
  },
  {
    "timestamp": 1767057238262.0,
    "timestamp_human": "2025-12-29T19:13:58.262597",
    "namespace": "llm",
    "pod": "llama-cpp-968bcbbbd-bjrj5",
    "container": "llama-server",
    "node": "node-2",
    "log_line": "warn: LLAMA_ARG_HOST environment variable is set, but will be overwritten by command line argument --host",
    "detected_severity": "WARN",
    "signature": "warn: LLAMA_ARG_HOST environment variable is set, but will be overwritten by command line argument --host",
    "signature_hash": "3a1208e2",
    "source": "real",
    "root_cause": "config_override_warning",
    "severity": "warn",
    "component": "llama_cpp",
    "summary": "Environment variable overridden by command-line argument (benign config precedence)",
    "action_needed": "none"
  },
  {
    "timestamp": 1766856599753.0,
    "timestamp_human": "2025-12-27T11:29:59.753564",
    "namespace": "llm",
    "pod": "llama-cpp-77c6884846-2rj47",
    "container": "llama-server",
    "node": "node-2",
    "log_line": "srv    send_error: task id = 5437, error: the request exceeds the available context size, try increasing it",
    "detected_severity": "ERROR",
    "signature": "srv    send_error: task id = 5437, error: the request exceeds the available context size, try increasing it",
    "signature_hash": "b6f579f4",
    "source": "real",
    "root_cause": "context_size_exceeded",
    "severity": "error",
    "component": "llama_cpp",
    "summary": "LLM request exceeded configured context window size",
    "action_needed": "increase_context_size"
  },
  {
    "timestamp": 1766773939620.0,
    "timestamp_human": "2025-12-26T12:32:19.620520",
    "namespace": "llm",
    "pod": "llama-cpp-77c6884846-2rj47",
    "container": "llama-server",
    "node": "node-2",
    "log_line": "srv    send_error: task id = 1808, error: the request exceeds the available context size, try increasing it",
    "detected_severity": "ERROR",
    "signature": "srv    send_error: task id = 1808, error: the request exceeds the available context size, try increasing it",
    "signature_hash": "28439804",
    "source": "real",
    "root_cause": "context_size_exceeded",
    "severity": "error",
    "component": "llama_cpp",
    "summary": "LLM request exceeded configured context window size",
    "action_needed": "increase_context_size"
  },
  {
    "timestamp": 1767120330116.0,
    "timestamp_human": "2025-12-30T12:45:30.116874",
    "namespace": "logging",
    "pod": "loki-0",
    "container": "loki",
    "node": "node-2",
    "log_line": "ts=2025-12-30T18:45:30.029765605Z caller=spanlogger.go:111 middleware=QueryShard.astMapperware org_id=fake user=fake caller=log.go:168 level=warn msg=\"failed mapping AST\" err=\"context canceled\" query=\"{namespace=\\\"log-analyzer\\\"} |~ \\\"(?i)(error|warn|critical|exception|failed)\\\"\"",
    "detected_severity": "CRITICAL",
    "signature": "ts=<TIMESTAMP> caller=spanlogger.go:<PORT> middleware=QueryShard.astMapperware org_id=fake user=fake caller=log.go:<PORT> level=warn msg=\"failed mapping AST\" err=\"context canceled\" query=\"{namespace=\\\"log-analyzer\\\"} |~ \\\"(?i)(error|warn|critical|exception|failed)\\\"\"",
    "signature_hash": "bae93254",
    "source": "real",
    "root_cause": "query_canceled",
    "severity": "warn",
    "component": "loki",
    "summary": "Loki query canceled by client before completion",
    "action_needed": "none"
  },
  {
    "timestamp": 1767120330116.0,
    "timestamp_human": "2025-12-30T12:45:30.116870",
    "namespace": "logging",
    "pod": "loki-0",
    "container": "loki",
    "node": "node-2",
    "log_line": "ts=2025-12-30T18:45:30.029766794Z caller=spanlogger.go:111 middleware=QueryShard.astMapperware org_id=fake user=fake caller=log.go:168 level=warn msg=\"failed mapping AST\" err=\"context canceled\" query=\"{namespace=\\\"log-analyzer\\\"} |~ \\\"(?i)(error|warn|critical|exception|failed)\\\"\"",
    "detected_severity": "CRITICAL",
    "signature": "ts=<TIMESTAMP> caller=spanlogger.go:<PORT> middleware=QueryShard.astMapperware org_id=fake user=fake caller=log.go:<PORT> level=warn msg=\"failed mapping AST\" err=\"context canceled\" query=\"{namespace=\\\"log-analyzer\\\"} |~ \\\"(?i)(error|warn|critical|exception|failed)\\\"\"",
    "signature_hash": "bae93254",
    "source": "real",
    "root_cause": "query_canceled",
    "severity": "warn",
    "component": "loki",
    "summary": "Loki query canceled by client before completion",
    "action_needed": "none"
  },
  {
    "timestamp": 1767120330186.0,
    "timestamp_human": "2025-12-30T12:45:30.186753",
    "namespace": "logging",
    "pod": "loki-0",
    "container": "loki",
    "node": "node-2",
    "log_line": "level=error ts=2025-12-30T18:45:30.120814769Z caller=scheduler_processor.go:175 component=querier org_id=fake msg=\"error notifying scheduler about finished query\" err=EOF addr=10.244.1.10:9095",
    "detected_severity": "ERROR",
    "signature": "level=error ts=<TIMESTAMP> caller=scheduler_processor.go:<PORT> component=querier org_id=fake msg=\"error notifying scheduler about finished query\" err=EOF addr=<IP>:<PORT>",
    "signature_hash": "2fa33429",
    "source": "real",
    "root_cause": "scheduler_communication_error",
    "severity": "error",
    "component": "loki",
    "summary": "Loki querier lost connection to scheduler while reporting query completion",
    "action_needed": "monitor"
  },
  {
    "timestamp": 1767120330186.0,
    "timestamp_human": "2025-12-30T12:45:30.186718",
    "namespace": "logging",
    "pod": "loki-0",
    "container": "loki",
    "node": "node-2",
    "log_line": "level=error ts=2025-12-30T18:45:30.119122586Z caller=scheduler_processor.go:175 component=querier org_id=fake msg=\"error notifying scheduler about finished query\" err=EOF addr=10.244.1.10:9095",
    "detected_severity": "ERROR",
    "signature": "level=error ts=<TIMESTAMP> caller=scheduler_processor.go:<PORT> component=querier org_id=fake msg=\"error notifying scheduler about finished query\" err=EOF addr=<IP>:<PORT>",
    "signature_hash": "2fa33429",
    "source": "real",
    "root_cause": "scheduler_communication_error",
    "severity": "error",
    "component": "loki",
    "summary": "Loki querier lost connection to scheduler while reporting query completion",
    "action_needed": "monitor"
  },
  {
    "timestamp": 1767120330186.0,
    "timestamp_human": "2025-12-30T12:45:30.186738",
    "namespace": "logging",
    "pod": "loki-0",
    "container": "loki",
    "node": "node-2",
    "log_line": "level=error ts=2025-12-30T18:45:30.120150676Z caller=scheduler_processor.go:111 component=querier msg=\"error processing requests from scheduler\" err=\"rpc error: code = Canceled desc = context canceled\" addr=10.244.1.10:9095",
    "detected_severity": "ERROR",
    "signature": "level=error ts=<TIMESTAMP> caller=scheduler_processor.go:<PORT> component=querier msg=\"error processing requests from scheduler\" err=\"rpc error: code = Canceled desc = context canceled\" addr=<IP>:<PORT>",
    "signature_hash": "7ad3a119",
    "source": "real",
    "root_cause": "scheduler_context_canceled",
    "severity": "error",
    "component": "loki",
    "summary": "Loki querier stopped processing requests due to context cancellation",
    "action_needed": "monitor"
  },
  {
    "timestamp": 1767120310244.0,
    "timestamp_human": "2025-12-30T12:45:10.244145",
    "namespace": "kube-system",
    "pod": "kube-controller-manager-node-1",
    "container": "kube-controller-manager",
    "node": "node-1",
    "log_line": "I1230 18:45:10.243882       1 garbagecollector.go:792] \"failed to discover some groups\" groups=\"map[\\\"metrics.k8s.io/v1beta1\\\":\\\"stale GroupVersion discovery: metrics.k8s.io/v1beta1\\\"]\"",
    "detected_severity": "ERROR",
    "signature": "I1230 18:<PORT>:<PORT>.243882       1 garbagecollector.go:<PORT>] \"failed to discover some groups\" groups=\"map[\\\"metrics.k8s.io/v1beta1\\\":\\\"stale GroupVersion discovery: metrics.k8s.io/v1beta1\\\"]\"",
    "signature_hash": "db050b36",
    "source": "real",
    "root_cause": "metrics_server_missing",
    "severity": "warn",
    "component": "kube_controller_manager",
    "summary": "Garbage collector cannot discover metrics API (metrics-server not installed)",
    "action_needed": "none"
  },
  {
    "timestamp": 1767120250196.0,
    "timestamp_human": "2025-12-30T12:44:10.196546",
    "namespace": "kube-system",
    "pod": "kube-controller-manager-node-1",
    "container": "kube-controller-manager",
    "node": "node-1",
    "log_line": "I1230 18:44:10.196298       1 garbagecollector.go:792] \"failed to discover some groups\" groups=\"map[\\\"metrics.k8s.io/v1beta1\\\":\\\"stale GroupVersion discovery: metrics.k8s.io/v1beta1\\\"]\"",
    "detected_severity": "ERROR",
    "signature": "I1230 18:<PORT>:<PORT>.196298       1 garbagecollector.go:<PORT>] \"failed to discover some groups\" groups=\"map[\\\"metrics.k8s.io/v1beta1\\\":\\\"stale GroupVersion discovery: metrics.k8s.io/v1beta1\\\"]\"",
    "signature_hash": "1aa8960c",
    "source": "real",
    "root_cause": "metrics_server_missing",
    "severity": "warn",
    "component": "kube_controller_manager",
    "summary": "Garbage collector cannot discover metrics API (metrics-server not installed)",
    "action_needed": "none"
  },
  {
    "timestamp": 1767120190151.0,
    "timestamp_human": "2025-12-30T12:43:10.151262",
    "namespace": "kube-system",
    "pod": "kube-controller-manager-node-1",
    "container": "kube-controller-manager",
    "node": "node-1",
    "log_line": "I1230 18:43:10.150951       1 garbagecollector.go:792] \"failed to discover some groups\" groups=\"map[\\\"metrics.k8s.io/v1beta1\\\":\\\"stale GroupVersion discovery: metrics.k8s.io/v1beta1\\\"]\"",
    "detected_severity": "ERROR",
    "signature": "I1230 18:<PORT>:<PORT>.150951       1 garbagecollector.go:<PORT>] \"failed to discover some groups\" groups=\"map[\\\"metrics.k8s.io/v1beta1\\\":\\\"stale GroupVersion discovery: metrics.k8s.io/v1beta1\\\"]\"",
    "signature_hash": "faf781d4",
    "source": "real",
    "root_cause": "metrics_server_missing",
    "severity": "warn",
    "component": "kube_controller_manager",
    "summary": "Garbage collector cannot discover metrics API (metrics-server not installed)",
    "action_needed": "none"
  },
  {
    "timestamp": 1767120130100.0,
    "timestamp_human": "2025-12-30T12:42:10.100356",
    "namespace": "kube-system",
    "pod": "kube-controller-manager-node-1",
    "container": "kube-controller-manager",
    "node": "node-1",
    "log_line": "I1230 18:42:10.100284       1 garbagecollector.go:792] \"failed to discover some groups\" groups=\"map[\\\"metrics.k8s.io/v1beta1\\\":\\\"stale GroupVersion discovery: metrics.k8s.io/v1beta1\\\"]\"",
    "detected_severity": "ERROR",
    "signature": "I1230 18:<PORT>:<PORT>.100284       1 garbagecollector.go:<PORT>] \"failed to discover some groups\" groups=\"map[\\\"metrics.k8s.io/v1beta1\\\":\\\"stale GroupVersion discovery: metrics.k8s.io/v1beta1\\\"]\"",
    "signature_hash": "f615146a",
    "source": "real",
    "root_cause": "metrics_server_missing",
    "severity": "warn",
    "component": "kube_controller_manager",
    "summary": "Garbage collector cannot discover metrics API (metrics-server not installed)",
    "action_needed": "none"
  },
  {
    "timestamp": 1767120070063.0,
    "timestamp_human": "2025-12-30T12:41:10.063422",
    "namespace": "kube-system",
    "pod": "kube-controller-manager-node-1",
    "container": "kube-controller-manager",
    "node": "node-1",
    "log_line": "I1230 18:41:10.063348       1 garbagecollector.go:792] \"failed to discover some groups\" groups=\"map[\\\"metrics.k8s.io/v1beta1\\\":\\\"stale GroupVersion discovery: metrics.k8s.io/v1beta1\\\"]\"",
    "detected_severity": "ERROR",
    "signature": "I1230 18:<PORT>:<PORT>.063348       1 garbagecollector.go:<PORT>] \"failed to discover some groups\" groups=\"map[\\\"metrics.k8s.io/v1beta1\\\":\\\"stale GroupVersion discovery: metrics.k8s.io/v1beta1\\\"]\"",
    "signature_hash": "9df3a046",
    "source": "real",
    "root_cause": "metrics_server_missing",
    "severity": "warn",
    "component": "kube_controller_manager",
    "summary": "Garbage collector cannot discover metrics API (metrics-server not installed)",
    "action_needed": "none"
  },
  {
    "timestamp": 1767120107047.0,
    "timestamp_human": "2025-12-30T12:41:47.047701",
    "namespace": "flux-system",
    "pod": "helm-controller-74988df57b-jbp6h",
    "container": "manager",
    "node": "node-2",
    "log_line": "{\"level\":\"info\",\"ts\":\"2025-12-30T18:41:47.047Z\",\"msg\":\"HelmChart 'flux-system/monitoring-prometheus' is not ready: invalid chart reference: failed to get chart version for remote reference: no chart name found\",\"controller\":\"helmrelease\",\"controllerGroup\":\"helm.toolkit.fluxcd.io\",\"controllerKind\":\"HelmRelease\",\"HelmRelease\":{\"name\":\"prometheus\",\"namespace\":\"monitoring\"},\"namespace\":\"monitoring\",\"name\":\"prometheus\",\"reconcileID\":\"e60c18e4-8f6c-4ca0-82c9-04984923fd89\"}",
    "detected_severity": "ERROR",
    "signature": "{\"level\":\"info\",\"ts\":\"<TIMESTAMP>\",\"msg\":\"HelmChart 'flux-system/monitoring-prometheus' is not ready: invalid chart reference: failed to get chart version for remote reference: no chart name found\",\"controller\":\"helmrelease\",\"controllerGroup\":\"helm.toolkit.fluxcd.io\",\"controllerKind\":\"HelmRelease\",\"HelmRelease\":{\"name\":\"prometheus\",\"namespace\":\"monitoring\"},\"namespace\":\"monitoring\",\"name\":\"prometheus\",\"reconcileID\":\"<UUID>\"}",
    "signature_hash": "0d4be2d4",
    "source": "real",
    "root_cause": "helm_chart_invalid_reference",
    "severity": "error",
    "component": "flux_helm_controller",
    "summary": "Flux cannot find chart name in HelmChart resource configuration",
    "action_needed": "fix_helm_chart_spec"
  },
  {
    "timestamp": 1767038406548.0,
    "timestamp_human": "2025-12-29T14:00:06.548313",
    "namespace": "flux-system",
    "pod": "helm-controller-74988df57b-jbp6h",
    "container": "manager",
    "node": "node-2",
    "log_line": "{\"level\":\"info\",\"ts\":\"2025-12-29T20:00:06.548Z\",\"msg\":\"release is in a failed state\",\"controller\":\"helmrelease\",\"controllerGroup\":\"helm.toolkit.fluxcd.io\",\"controllerKind\":\"HelmRelease\",\"HelmRelease\":{\"name\":\"tempo\",\"namespace\":\"logging\"},\"namespace\":\"logging\",\"name\":\"tempo\",\"reconcileID\":\"28949acd-3843-47d8-a04e-4334afe61a7b\"}",
    "detected_severity": "ERROR",
    "signature": "{\"level\":\"info\",\"ts\":\"<TIMESTAMP>\",\"msg\":\"release is in a failed state\",\"controller\":\"helmrelease\",\"controllerGroup\":\"helm.toolkit.fluxcd.io\",\"controllerKind\":\"HelmRelease\",\"HelmRelease\":{\"name\":\"tempo\",\"namespace\":\"logging\"},\"namespace\":\"logging\",\"name\":\"tempo\",\"reconcileID\":\"<UUID>\"}",
    "signature_hash": "d12338c5",
    "source": "real",
    "root_cause": "helm_release_failed",
    "severity": "error",
    "component": "flux_helm_controller",
    "summary": "Helm release for Tempo is in failed state",
    "action_needed": "check_helm_release"
  },
  {
    "timestamp": 1767120049371.0,
    "timestamp_human": "2025-12-30T12:40:49.371182",
    "namespace": "flux-system",
    "pod": "source-controller-56c7f45479-5c7s2",
    "container": "manager",
    "node": "node-2",
    "log_line": "{\"level\":\"error\",\"ts\":\"2025-12-30T18:40:49.370Z\",\"msg\":\"reconciliation stalled\",\"controller\":\"helmchart\",\"controllerGroup\":\"source.toolkit.fluxcd.io\",\"controllerKind\":\"HelmChart\",\"HelmChart\":{\"name\":\"monitoring-prometheus\",\"namespace\":\"flux-system\"},\"namespace\":\"flux-system\",\"name\":\"monitoring-prometheus\",\"reconcileID\":\"fc8cc145-b97d-412f-81c1-08b73a985ba0\",\"error\":\"invalid chart reference: failed to get chart version for remote reference: no chart name found\"}",
    "detected_severity": "ERROR",
    "signature": "{\"level\":\"error\",\"ts\":\"<TIMESTAMP>\",\"msg\":\"reconciliation stalled\",\"controller\":\"helmchart\",\"controllerGroup\":\"source.toolkit.fluxcd.io\",\"controllerKind\":\"HelmChart\",\"HelmChart\":{\"name\":\"monitoring-prometheus\",\"namespace\":\"flux-system\"},\"namespace\":\"flux-system\",\"name\":\"monitoring-prometheus\",\"reconcileID\":\"<UUID>\",\"error\":\"invalid chart reference: failed to get chart version for remote reference: no chart name found\"}",
    "signature_hash": "dae70660",
    "source": "real",
    "root_cause": "helm_chart_reconciliation_stalled",
    "severity": "error",
    "component": "flux_source_controller",
    "summary": "Flux source controller cannot reconcile HelmChart due to missing chart name",
    "action_needed": "fix_helm_chart_spec"
  },
  {
    "timestamp": 1767036880576.0,
    "timestamp_human": "2025-12-29T13:34:40.576716",
    "namespace": "flux-system",
    "pod": "source-controller-56c7f45479-5c7s2",
    "container": "manager",
    "node": "node-2",
    "log_line": "{\"level\":\"error\",\"ts\":\"2025-12-29T19:34:40.576Z\",\"msg\":\"Reconciler error\",\"controller\":\"helmrepository\",\"controllerGroup\":\"source.toolkit.fluxcd.io\",\"controllerKind\":\"HelmRepository\",\"HelmRepository\":{\"name\":\"envoyproxy\",\"namespace\":\"flux-system\"},\"namespace\":\"flux-system\",\"name\":\"envoyproxy\",\"reconcileID\":\"e7e74e97-873b-465b-92d7-6a6f573f359e\",\"error\":\"failed to fetch Helm repository index: failed to cache index to temporary file: failed to fetch https://gateway.envoyproxy.io/index.yaml : 404 Not Found\"}",
    "detected_severity": "ERROR",
    "signature": "{\"level\":\"error\",\"ts\":\"<TIMESTAMP>\",\"msg\":\"Reconciler error\",\"controller\":\"helmrepository\",\"controllerGroup\":\"source.toolkit.fluxcd.io\",\"controllerKind\":\"HelmRepository\",\"HelmRepository\":{\"name\":\"envoyproxy\",\"namespace\":\"flux-system\"},\"namespace\":\"flux-system\",\"name\":\"envoyproxy\",\"reconcileID\":\"<UUID>\",\"error\":\"failed to fetch Helm repository index: failed to cache index to temporary file: failed to fetch https://gateway.envoyproxy.io/index.yaml : 404 Not Found\"}",
    "signature_hash": "eb81f879",
    "source": "real",
    "root_cause": "helm_repo_url_invalid",
    "severity": "error",
    "component": "flux_source_controller",
    "summary": "Helm repository index URL returns 404 (likely wrong URL or moved)",
    "action_needed": "update_helm_repo_url"
  },
  {
    "timestamp": 1767037346801.0,
    "timestamp_human": "2025-12-29T13:42:26.801024",
    "namespace": "flux-system",
    "pod": "helm-controller-74988df57b-jbp6h",
    "container": "manager",
    "node": "node-2",
    "log_line": "{\"level\":\"error\",\"ts\":\"2025-12-29T19:42:26.800Z\",\"msg\":\"Reconciler error\",\"controller\":\"helmrelease\",\"controllerGroup\":\"helm.toolkit.fluxcd.io\",\"controllerKind\":\"HelmRelease\",\"HelmRelease\":{\"name\":\"grafana\",\"namespace\":\"logging\"},\"namespace\":\"logging\",\"name\":\"grafana\",\"reconcileID\":\"e79228e1-bd08-48eb-9019-7b7d00b09697\",\"error\":\"terminal error: exceeded maximum retries: cannot remediate failed release\"}",
    "detected_severity": "ERROR",
    "signature": "{\"level\":\"error\",\"ts\":\"<TIMESTAMP>\",\"msg\":\"Reconciler error\",\"controller\":\"helmrelease\",\"controllerGroup\":\"helm.toolkit.fluxcd.io\",\"controllerKind\":\"HelmRelease\",\"HelmRelease\":{\"name\":\"grafana\",\"namespace\":\"logging\"},\"namespace\":\"logging\",\"name\":\"grafana\",\"reconcileID\":\"<UUID>\",\"error\":\"terminal error: exceeded maximum retries: cannot remediate failed release\"}",
    "signature_hash": "5ea92b55",
    "source": "real",
    "root_cause": "helm_release_max_retries",
    "severity": "critical",
    "component": "flux_helm_controller",
    "summary": "Flux exhausted retry attempts and cannot remediate failed Grafana release",
    "action_needed": "manual_helm_intervention"
  },
  {
    "timestamp": 1767054957303.0,
    "timestamp_human": "2025-12-29T18:35:57.303580",
    "namespace": "envoy-gateway-system",
    "pod": "envoy-gateway-c9dd54486-csq78",
    "container": "envoy-gateway",
    "node": "node-2",
    "log_line": "2025-12-30T00:35:57.303Z\tINFO\tprovider.KubeAPIWarningLogger\tlog/warning_handler.go:65\tmetadata.finalizers: \"gateway-exists-finalizer.gateway.networking.k8s.io\": prefer a domain-qualified finalizer name including a path (/) to avoid accidental conflicts with other finalizer writers\t{\"runner\": \"provider\"}",
    "detected_severity": "WARN",
    "signature": "<TIMESTAMP>\tINFO\tprovider.KubeAPIWarningLogger\tlog/warning_handler.go:<PORT>\tmetadata.finalizers: \"gateway-<POD>izer.gateway.networking.k8s.io\": prefer a domain-qualified finalizer name including a path (/) to avoid accidental conflicts with other finalizer writers\t{\"runner\": \"provider\"}",
    "signature_hash": "1bef9e42",
    "source": "real",
    "root_cause": "k8s_api_deprecation_warning",
    "severity": "info",
    "component": "envoy_gateway",
    "summary": "Kubernetes API warning about finalizer naming convention (non-critical)",
    "action_needed": "none"
  },
  {
    "timestamp": 1766970705891.0,
    "timestamp_human": "2025-12-28T19:11:45.891271",
    "namespace": "envoy-gateway-system",
    "pod": "envoy-gateway-775d8bf958-ldd5t",
    "container": "envoy-gateway",
    "node": "node-1",
    "log_line": "2025-12-29T01:11:45.890Z\tERROR\tprovider\tleaderelection/leaderelection.go:429\tFailed to update lock optimistically: Put \"https://10.43.0.1:443/apis/coordination.k8s.io/v1/namespaces/envoy-gateway-system/leases/5b9825d2.gateway.envoyproxy.io?timeout=5s\": dial tcp 10.43.0.1:443: connect: connection refused, falling back to slow path\t{\"runner\": \"provider\"}",
    "detected_severity": "ERROR",
    "signature": "<TIMESTAMP>\tERROR\tprovider\tleaderelection/leaderelection.go:<PORT>\tFailed to update lock optimistically: Put \"https://<IP>:<PORT>/apis/coordination.k8s.io/v1/namespaces/envoy-<POD>m/leases/5b9825d2.gateway.envoyproxy.io?timeout=5s\": dial tcp <IP>:<PORT>: connect: connection refused, falling back to slow path\t{\"runner\": \"provider\"}",
    "signature_hash": "0e3bf612",
    "source": "real",
    "root_cause": "leader_election_apiserver_unavailable",
    "severity": "error",
    "component": "envoy_gateway",
    "summary": "Envoy Gateway cannot reach API server for leader election, using fallback",
    "action_needed": "check_apiserver_connectivity"
  },
  {
    "timestamp": 1766958940716.0,
    "timestamp_human": "2025-12-28T15:55:40.716501",
    "namespace": "envoy-gateway-system",
    "pod": "envoy-gateway-775d8bf958-ldd5t",
    "container": "envoy-gateway",
    "node": "node-1",
    "log_line": "2025-12-28T21:55:40.373Z\tERROR\tprovider\tcache/reflector.go:200\tFailed to watch\t{\"runner\": \"provider\", \"logger\": \"UnhandledError\", \"reflector\": \"pkg/mod/k8s.io/client-go@v0.33.0/tools/cache/reflector.go:285\", \"type\": \"*v1.Deployment\", \"error\": \"apiserver not ready\"}",
    "detected_severity": "ERROR",
    "signature": "<TIMESTAMP>\tERROR\tprovider\tcache/reflector.go:<PORT>\tFailed to watch\t{\"runner\": \"provider\", \"logger\": \"UnhandledError\", \"reflector\": \"pkg/mod/k8s.io/client-go@v0.33.0/tools/cache/reflector.go:<PORT>\", \"type\": \"*v1.Deployment\", \"error\": \"apiserver not ready\"}",
    "signature_hash": "a3ff94e2",
    "source": "real",
    "root_cause": "apiserver_not_ready",
    "severity": "error",
    "component": "envoy_gateway",
    "summary": "Envoy Gateway cannot watch Deployments because API server is not ready",
    "action_needed": "wait_for_apiserver"
  },
  {
    "timestamp": 1766958940716.0,
    "timestamp_human": "2025-12-28T15:55:40.716490",
    "namespace": "envoy-gateway-system",
    "pod": "envoy-gateway-775d8bf958-ldd5t",
    "container": "envoy-gateway",
    "node": "node-1",
    "log_line": "2025-12-28T21:55:40.307Z\tERROR\tprovider\tcache/reflector.go:200\tFailed to watch\t{\"runner\": \"provider\", \"logger\": \"UnhandledError\", \"reflector\": \"pkg/mod/k8s.io/client-go@v0.33.0/tools/cache/reflector.go:285\", \"type\": \"*v1alpha2.TCPRoute\", \"error\": \"apiserver not ready\"}",
    "detected_severity": "ERROR",
    "signature": "<TIMESTAMP>\tERROR\tprovider\tcache/reflector.go:<PORT>\tFailed to watch\t{\"runner\": \"provider\", \"logger\": \"UnhandledError\", \"reflector\": \"pkg/mod/k8s.io/client-go@v0.33.0/tools/cache/reflector.go:<PORT>\", \"type\": \"*v1alpha2.TCPRoute\", \"error\": \"apiserver not ready\"}",
    "signature_hash": "4ecdbd71",
    "source": "real",
    "root_cause": "apiserver_not_ready",
    "severity": "error",
    "component": "envoy_gateway",
    "summary": "Envoy Gateway cannot watch TCPRoutes because API server is not ready",
    "action_needed": "wait_for_apiserver"
  },
  {
    "timestamp": 1766958940716.0,
    "timestamp_human": "2025-12-28T15:55:40.716482",
    "namespace": "envoy-gateway-system",
    "pod": "envoy-gateway-775d8bf958-ldd5t",
    "container": "envoy-gateway",
    "node": "node-1",
    "log_line": "2025-12-28T21:55:40.272Z\tERROR\tprovider\tcache/reflector.go:200\tFailed to watch\t{\"runner\": \"provider\", \"logger\": \"UnhandledError\", \"reflector\": \"pkg/mod/k8s.io/client-go@v0.33.0/tools/cache/reflector.go:285\", \"type\": \"*v1alpha1.BackendTrafficPolicy\", \"error\": \"apiserver not ready\"}",
    "detected_severity": "ERROR",
    "signature": "<TIMESTAMP>\tERROR\tprovider\tcache/reflector.go:<PORT>\tFailed to watch\t{\"runner\": \"provider\", \"logger\": \"UnhandledError\", \"reflector\": \"pkg/mod/k8s.io/client-go@v0.33.0/tools/cache/reflector.go:<PORT>\", \"type\": \"*v1alpha1.BackendTrafficPolicy\", \"error\": \"apiserver not ready\"}",
    "signature_hash": "f966c5e2",
    "source": "real",
    "root_cause": "apiserver_not_ready",
    "severity": "error",
    "component": "envoy_gateway",
    "summary": "Envoy Gateway cannot watch BackendTrafficPolicy because API server is not ready",
    "action_needed": "wait_for_apiserver"
  }
]
