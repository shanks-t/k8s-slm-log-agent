[
  {
    "timestamp": 1766954816856.0,
    "timestamp_human": "2025-12-28T14:46:56.856733",
    "namespace": "log-analyzer",
    "pod": "log-analyzer-7669d66676-gvm8p",
    "container": "log-analyzer",
    "node": "node-1",
    "log_line": "{\"timestamp\": \"2025-12-28 20:46:56,856\", \"level\": \"WARNING\", \"logger\": \"opentelemetry.exporter.otlp.proto.grpc.exporter\", \"message\": \"Transient error StatusCode.UNAVAILABLE encountered while exporting traces to tempo.logging.svc.cluster.local:4317, retrying in 0.91s.\"}",
    "detected_severity": "ERROR",
    "signature": "{\"timestamp\": \"<TIMESTAMP>,856\", \"level\": \"WARNING\", \"logger\": \"opentelemetry.exporter.otlp.proto.grpc.exporter\", \"message\": \"Transient error StatusCode.UNAVAILABLE encountered while exporting traces to tempo.logging.svc.cluster.local:<PORT>, retrying in 0.91s.\"}",
    "signature_hash": "562e4ddb",
    "source": "real",
    "root_cause": "tempo_unavailable",
    "severity": "warn",
    "component": "opentelemetry_exporter",
    "summary": "OpenTelemetry exporter cannot reach Tempo service, retrying with backoff",
    "action_needed": "monitor"
  },
  {
    "timestamp": 1766954787613.0,
    "timestamp_human": "2025-12-28T14:46:27.613006",
    "namespace": "log-analyzer",
    "pod": "log-analyzer-7669d66676-gvm8p",
    "container": "log-analyzer",
    "node": "node-1",
    "log_line": "{\"timestamp\": \"2025-12-28 20:46:27,612\", \"level\": \"WARNING\", \"logger\": \"opentelemetry.exporter.otlp.proto.grpc.exporter\", \"message\": \"Transient error StatusCode.UNAVAILABLE encountered while exporting traces to tempo.logging.svc.cluster.local:4317, retrying in 1.17s.\"}",
    "detected_severity": "ERROR",
    "signature": "{\"timestamp\": \"<TIMESTAMP>,612\", \"level\": \"WARNING\", \"logger\": \"opentelemetry.exporter.otlp.proto.grpc.exporter\", \"message\": \"Transient error StatusCode.UNAVAILABLE encountered while exporting traces to tempo.logging.svc.cluster.local:<PORT>, retrying in 1.17s.\"}",
    "signature_hash": "6eb5ed2a",
    "source": "real",
    "root_cause": "tempo_unavailable",
    "severity": "warn",
    "component": "opentelemetry_exporter",
    "summary": "OpenTelemetry exporter cannot reach Tempo service, retrying with backoff",
    "action_needed": "monitor"
  },
  {
    "timestamp": 1766866954843.0,
    "timestamp_human": "2025-12-27T14:22:34.843813",
    "namespace": "log-analyzer",
    "pod": "log-analyzer-7669d66676-gvm8p",
    "container": "log-analyzer",
    "node": "node-1",
    "log_line": "{\"timestamp\": \"2025-12-27 20:22:34,843\", \"level\": \"WARNING\", \"logger\": \"log_analyzer.main\", \"message\": \"No logs found in Loki\", \"trace_id\": \"7d74b07deccc3c4ed47221ec5bbf94b8\", \"span_id\": \"dca17329fde9d9d1\", \"trace_flags\": 1}",
    "detected_severity": "WARN",
    "signature": "{\"timestamp\": \"<TIMESTAMP>,843\", \"level\": \"WARNING\", \"logger\": \"log_analyzer.main\", \"message\": \"No logs found in Loki\", \"trace_id\": \"<HEXID>\", \"span_id\": \"<HEXID>\", \"trace_flags\": 1}",
    "signature_hash": "18c29867",
    "source": "real",
    "root_cause": "empty_query_result",
    "severity": "warn",
    "component": "log_analyzer_api",
    "summary": "User query returned no logs from Loki",
    "action_needed": "none"
  },
  {
    "timestamp": 1766862724118.0,
    "timestamp_human": "2025-12-27T13:12:04.118720",
    "namespace": "log-analyzer",
    "pod": "log-analyzer-7669d66676-gvm8p",
    "container": "log-analyzer",
    "node": "node-1",
    "log_line": "{\"timestamp\": \"2025-12-27 19:12:04,118\", \"level\": \"WARNING\", \"logger\": \"log_analyzer.main\", \"message\": \"No logs found in Loki\", \"trace_id\": \"ce95c12a38bc999d5f7436966cb5fa6c\", \"span_id\": \"aa7b6e167927edd2\", \"trace_flags\": 1}",
    "detected_severity": "WARN",
    "signature": "{\"timestamp\": \"<TIMESTAMP>,118\", \"level\": \"WARNING\", \"logger\": \"log_analyzer.main\", \"message\": \"No logs found in Loki\", \"trace_id\": \"<HEXID>\", \"span_id\": \"<HEXID>\", \"trace_flags\": 1}",
    "signature_hash": "f05a7e1d",
    "source": "real",
    "root_cause": "empty_query_result",
    "severity": "warn",
    "component": "log_analyzer_api",
    "summary": "User query returned no logs from Loki",
    "action_needed": "none"
  },
  {
    "timestamp": 1766856667039.0,
    "timestamp_human": "2025-12-27T11:31:07.039947",
    "namespace": "log-analyzer",
    "pod": "log-analyzer-7669d66676-gvm8p",
    "container": "log-analyzer",
    "node": "node-1",
    "log_line": "{\"timestamp\": \"2025-12-27 17:31:07,039\", \"level\": \"WARNING\", \"logger\": \"log_analyzer.main\", \"message\": \"No logs found in Loki\", \"trace_id\": \"9b42ab72bfecdb5173e78219e7c7f613\", \"span_id\": \"abed149e27f16f3a\", \"trace_flags\": 1}",
    "detected_severity": "WARN",
    "signature": "{\"timestamp\": \"<TIMESTAMP>,039\", \"level\": \"WARNING\", \"logger\": \"log_analyzer.main\", \"message\": \"No logs found in Loki\", \"trace_id\": \"<HEXID>\", \"span_id\": \"<HEXID>\", \"trace_flags\": 1}",
    "signature_hash": "b9a14e51",
    "source": "real",
    "root_cause": "empty_query_result",
    "severity": "warn",
    "component": "log_analyzer_api",
    "summary": "User query returned no logs from Loki",
    "action_needed": "none"
  },
  {
    "timestamp": 1766855724159.0,
    "timestamp_human": "2025-12-27T11:15:24.159865",
    "namespace": "log-analyzer",
    "pod": "log-analyzer-7669d66676-gvm8p",
    "container": "log-analyzer",
    "node": "node-1",
    "log_line": "{\"timestamp\": \"2025-12-27 17:15:24,159\", \"level\": \"WARNING\", \"logger\": \"log_analyzer.main\", \"message\": \"No logs found in Loki\", \"trace_id\": \"dcc2c4f6a175863646845f59958094bc\", \"span_id\": \"9c48e4f1c47865a5\", \"trace_flags\": 1}",
    "detected_severity": "WARN",
    "signature": "{\"timestamp\": \"<TIMESTAMP>,159\", \"level\": \"WARNING\", \"logger\": \"log_analyzer.main\", \"message\": \"No logs found in Loki\", \"trace_id\": \"dcc2c4f6a<TIMESTAMP>f59958094bc\", \"span_id\": \"<HEXID>\", \"trace_flags\": 1}",
    "signature_hash": "30713d89",
    "source": "real",
    "root_cause": "empty_query_result",
    "severity": "warn",
    "component": "log_analyzer_api",
    "summary": "User query returned no logs from Loki",
    "action_needed": "none"
  },
  {
    "timestamp": 1766798888497.0,
    "timestamp_human": "2025-12-26T19:28:08.497090",
    "namespace": "log-analyzer",
    "pod": "log-analyzer-66c94c6bcf-lxrbk",
    "container": "log-analyzer",
    "node": "node-1",
    "log_line": "{\"timestamp\": \"2025-12-27 01:28:08,496\", \"level\": \"WARNING\", \"logger\": \"log_analyzer.main\", \"message\": \"No logs found in Loki\", \"trace_id\": \"467cc545a36313aefa609ddf13eceac6\", \"span_id\": \"9708871c3e0eab95\", \"trace_flags\": 1}",
    "detected_severity": "WARN",
    "signature": "{\"timestamp\": \"<TIMESTAMP>,496\", \"level\": \"WARNING\", \"logger\": \"log_analyzer.main\", \"message\": \"No logs found in Loki\", \"trace_id\": \"<HEXID>\", \"span_id\": \"<HEXID>\", \"trace_flags\": 1}",
    "signature_hash": "63dd1e27",
    "source": "real",
    "root_cause": "empty_query_result",
    "severity": "warn",
    "component": "log_analyzer_api",
    "summary": "User query returned no logs from Loki",
    "action_needed": "none"
  },
  {
    "timestamp": 1766798882386.0,
    "timestamp_human": "2025-12-26T19:28:02.386131",
    "namespace": "log-analyzer",
    "pod": "log-analyzer-66c94c6bcf-lxrbk",
    "container": "log-analyzer",
    "node": "node-1",
    "log_line": "{\"timestamp\": \"2025-12-27 01:28:02,386\", \"level\": \"WARNING\", \"logger\": \"log_analyzer.main\", \"message\": \"No logs found in Loki\", \"trace_id\": \"7aaa2dbd7c7ce8539e9e2d46438d20f7\", \"span_id\": \"ffbca2a46303718a\", \"trace_flags\": 1}",
    "detected_severity": "WARN",
    "signature": "{\"timestamp\": \"<TIMESTAMP>,386\", \"level\": \"WARNING\", \"logger\": \"log_analyzer.main\", \"message\": \"No logs found in Loki\", \"trace_id\": \"<HEXID>\", \"span_id\": \"<HEXID>\", \"trace_flags\": 1}",
    "signature_hash": "d5a2f1b0",
    "source": "real",
    "root_cause": "empty_query_result",
    "severity": "warn",
    "component": "log_analyzer_api",
    "summary": "User query returned no logs from Loki",
    "action_needed": "none"
  },
  {
    "timestamp": 1766854348149.0,
    "timestamp_human": "2025-12-27T10:52:28.149094",
    "namespace": "log-analyzer",
    "pod": "log-analyzer-66c94c6bcf-gq4cc",
    "container": "log-analyzer",
    "node": "node-1",
    "log_line": "{\"timestamp\": \"2025-12-27 16:52:28,148\", \"level\": \"WARNING\", \"logger\": \"log_analyzer.main\", \"message\": \"No logs found in Loki\", \"trace_id\": \"e7b231d8999e4a26f86d00e9b7dae4ea\", \"span_id\": \"97e57d7a70134233\", \"trace_flags\": 1}",
    "detected_severity": "WARN",
    "signature": "{\"timestamp\": \"<TIMESTAMP>,148\", \"level\": \"WARNING\", \"logger\": \"log_analyzer.main\", \"message\": \"No logs found in Loki\", \"trace_id\": \"<HEXID>\", \"span_id\": \"<HEXID>\", \"trace_flags\": 1}",
    "signature_hash": "db9c8b25",
    "source": "real",
    "root_cause": "empty_query_result",
    "severity": "warn",
    "component": "log_analyzer_api",
    "summary": "User query returned no logs from Loki",
    "action_needed": "none"
  },
  {
    "timestamp": 1766854004119.0,
    "timestamp_human": "2025-12-27T10:46:44.119084",
    "namespace": "log-analyzer",
    "pod": "log-analyzer-66c94c6bcf-gq4cc",
    "container": "log-analyzer",
    "node": "node-1",
    "log_line": "{\"timestamp\": \"2025-12-27 16:46:44,118\", \"level\": \"WARNING\", \"logger\": \"log_analyzer.main\", \"message\": \"No logs found in Loki\", \"trace_id\": \"149f972695eacb279242141815053dec\", \"span_id\": \"bf30eb61ad4cec39\", \"trace_flags\": 1}",
    "detected_severity": "WARN",
    "signature": "{\"timestamp\": \"<TIMESTAMP>,118\", \"level\": \"WARNING\", \"logger\": \"log_analyzer.main\", \"message\": \"No logs found in Loki\", \"trace_id\": \"<HEXID><TIMESTAMP>53dec\", \"span_id\": \"<HEXID>\", \"trace_flags\": 1}",
    "signature_hash": "0b48f650",
    "source": "real",
    "root_cause": "empty_query_result",
    "severity": "warn",
    "component": "log_analyzer_api",
    "summary": "User query returned no logs from Loki",
    "action_needed": "none"
  },
  {
    "timestamp": 1766799190264.0,
    "timestamp_human": "2025-12-26T19:33:10.264970",
    "namespace": "log-analyzer",
    "pod": "log-analyzer-66c94c6bcf-gq4cc",
    "container": "log-analyzer",
    "node": "node-1",
    "log_line": "{\"timestamp\": \"2025-12-27 01:33:10,264\", \"level\": \"WARNING\", \"logger\": \"log_analyzer.main\", \"message\": \"No logs found in Loki\", \"trace_id\": \"5fc0b2afcad76ec2bb39fbcf3853cb63\", \"span_id\": \"fa2cdf76192ab4b6\", \"trace_flags\": 1}",
    "detected_severity": "WARN",
    "signature": "{\"timestamp\": \"<TIMESTAMP>,264\", \"level\": \"WARNING\", \"logger\": \"log_analyzer.main\", \"message\": \"No logs found in Loki\", \"trace_id\": \"<HEXID>\", \"span_id\": \"<HEXID>\", \"trace_flags\": 1}",
    "signature_hash": "15a9d515",
    "source": "real",
    "root_cause": "empty_query_result",
    "severity": "warn",
    "component": "log_analyzer_api",
    "summary": "User query returned no logs from Loki",
    "action_needed": "none"
  },
  {
    "timestamp": 1767055580435.0,
    "timestamp_human": "2025-12-29T18:46:20.435071",
    "namespace": "log-analyzer",
    "pod": "log-analyzer-6579fdbfb-jzlq7",
    "container": "log-analyzer",
    "node": "node-1",
    "log_line": "{\"timestamp\": \"2025-12-30 00:46:20,434\", \"level\": \"WARNING\", \"logger\": \"log_analyzer.main\", \"message\": \"No logs found in Loki\", \"trace_id\": \"9c86cc24ff82661f6d4e0b69f77a8ac2\", \"span_id\": \"e2ed75187ee73153\", \"trace_flags\": 1}",
    "detected_severity": "WARN",
    "signature": "{\"timestamp\": \"<TIMESTAMP>,434\", \"level\": \"WARNING\", \"logger\": \"log_analyzer.main\", \"message\": \"No logs found in Loki\", \"trace_id\": \"<HEXID>\", \"span_id\": \"<HEXID>\", \"trace_flags\": 1}",
    "signature_hash": "6726ea59",
    "source": "real",
    "root_cause": "empty_query_result",
    "severity": "warn",
    "component": "log_analyzer_api",
    "summary": "User query returned no logs from Loki",
    "action_needed": "none"
  },
  {
    "timestamp": 1767055556746.0,
    "timestamp_human": "2025-12-29T18:45:56.746266",
    "namespace": "log-analyzer",
    "pod": "log-analyzer-6579fdbfb-jzlq7",
    "container": "log-analyzer",
    "node": "node-1",
    "log_line": "{\"timestamp\": \"2025-12-30 00:45:56,746\", \"level\": \"WARNING\", \"logger\": \"log_analyzer.main\", \"message\": \"No logs found in Loki\", \"trace_id\": \"e3bd4f2e769e3323730f22505810f0eb\", \"span_id\": \"e220682e015bcfb6\", \"trace_flags\": 1}",
    "detected_severity": "WARN",
    "signature": "{\"timestamp\": \"<TIMESTAMP>,746\", \"level\": \"WARNING\", \"logger\": \"log_analyzer.main\", \"message\": \"No logs found in Loki\", \"trace_id\": \"<HEXID>\", \"span_id\": \"<HEXID>\", \"trace_flags\": 1}",
    "signature_hash": "5e76dd87",
    "source": "real",
    "root_cause": "empty_query_result",
    "severity": "warn",
    "component": "log_analyzer_api",
    "summary": "User query returned no logs from Loki",
    "action_needed": "none"
  },
  {
    "timestamp": 1767057111154.0,
    "timestamp_human": "2025-12-29T19:11:51.154739",
    "namespace": "log-analyzer",
    "pod": "log-analyzer-6579fdbfb-jzlq7",
    "container": "log-analyzer",
    "node": "node-1",
    "log_line": "raise HTTPStatusError(message, request=request, response=self)",
    "detected_severity": "ERROR",
    "signature": "raise HTTPStatusError(message, request=request, response=self)",
    "signature_hash": "e742940f",
    "source": "real",
    "root_cause": "http_client_error",
    "severity": "error",
    "component": "log_analyzer_api",
    "summary": "HTTP client error when calling downstream service",
    "action_needed": "investigate"
  },
  {
    "timestamp": 1767056653332.0,
    "timestamp_human": "2025-12-29T19:04:13.332529",
    "namespace": "log-analyzer",
    "pod": "log-analyzer-6579fdbfb-jzlq7",
    "container": "log-analyzer",
    "node": "node-1",
    "log_line": "raise HTTPStatusError(message, request=request, response=self)",
    "detected_severity": "ERROR",
    "signature": "raise HTTPStatusError(message, request=request, response=self)",
    "signature_hash": "e742940f",
    "source": "real",
    "root_cause": "http_client_error",
    "severity": "error",
    "component": "log_analyzer_api",
    "summary": "HTTP client error when calling downstream service",
    "action_needed": "investigate"
  },
  {
    "timestamp": 1767057111154.0,
    "timestamp_human": "2025-12-29T19:11:51.154501",
    "namespace": "log-analyzer",
    "pod": "log-analyzer-6579fdbfb-jzlq7",
    "container": "log-analyzer",
    "node": "node-1",
    "log_line": "File \"/usr/local/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app",
    "detected_severity": "ERROR",
    "signature": "File \"/usr/local/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app",
    "signature_hash": "f019416e",
    "source": "real",
    "root_cause": "exception_stacktrace",
    "severity": "error",
    "component": "log_analyzer_api",
    "summary": "Python exception stacktrace fragment from FastAPI handler",
    "action_needed": "investigate"
  },
  {
    "timestamp": 1767057111154.0,
    "timestamp_human": "2025-12-29T19:11:51.154366",
    "namespace": "log-analyzer",
    "pod": "log-analyzer-6579fdbfb-jzlq7",
    "container": "log-analyzer",
    "node": "node-1",
    "log_line": "File \"/usr/local/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app",
    "detected_severity": "ERROR",
    "signature": "File \"/usr/local/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app",
    "signature_hash": "f019416e",
    "source": "real",
    "root_cause": "exception_stacktrace",
    "severity": "error",
    "component": "log_analyzer_api",
    "summary": "Python exception stacktrace fragment from FastAPI handler",
    "action_needed": "investigate"
  },
  {
    "timestamp": 1767057111154.0,
    "timestamp_human": "2025-12-29T19:11:51.154483",
    "namespace": "log-analyzer",
    "pod": "log-analyzer-6579fdbfb-jzlq7",
    "container": "log-analyzer",
    "node": "node-1",
    "log_line": "File \"/usr/local/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app",
    "detected_severity": "ERROR",
    "signature": "File \"/usr/local/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app",
    "signature_hash": "c37472e6",
    "source": "real",
    "root_cause": "exception_stacktrace",
    "severity": "error",
    "component": "log_analyzer_api",
    "summary": "Python exception stacktrace fragment from FastAPI request handler",
    "action_needed": "investigate"
  },
  {
    "timestamp": 1767057111154.0,
    "timestamp_human": "2025-12-29T19:11:51.154353",
    "namespace": "log-analyzer",
    "pod": "log-analyzer-6579fdbfb-jzlq7",
    "container": "log-analyzer",
    "node": "node-1",
    "log_line": "File \"/usr/local/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app",
    "detected_severity": "ERROR",
    "signature": "File \"/usr/local/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app",
    "signature_hash": "c37472e6",
    "source": "real",
    "root_cause": "exception_stacktrace",
    "severity": "error",
    "component": "log_analyzer_api",
    "summary": "Python exception stacktrace fragment from FastAPI request handler",
    "action_needed": "investigate"
  },
  {
    "timestamp": 1767057111154.0,
    "timestamp_human": "2025-12-29T19:11:51.154456",
    "namespace": "log-analyzer",
    "pod": "log-analyzer-6579fdbfb-jzlq7",
    "container": "log-analyzer",
    "node": "node-1",
    "log_line": "await wrap_app_handling_exceptions(app, request)(scope, receive, send)",
    "detected_severity": "ERROR",
    "signature": "await wrap_app_handling_exceptions(app, request)(scope, receive, send)",
    "signature_hash": "49a01c82",
    "source": "real",
    "root_cause": "unknown",
    "severity": "error",
    "component": "log_analyzer",
    "summary": "Log from log-analyzer requiring manual review",
    "action_needed": "investigate"
  },
  {
    "timestamp": 1767056653332.0,
    "timestamp_human": "2025-12-29T19:04:13.332347",
    "namespace": "log-analyzer",
    "pod": "log-analyzer-6579fdbfb-jzlq7",
    "container": "log-analyzer",
    "node": "node-1",
    "log_line": "await wrap_app_handling_exceptions(app, request)(scope, receive, send)",
    "detected_severity": "ERROR",
    "signature": "await wrap_app_handling_exceptions(app, request)(scope, receive, send)",
    "signature_hash": "49a01c82",
    "source": "real",
    "root_cause": "unknown",
    "severity": "error",
    "component": "log_analyzer",
    "summary": "Log from log-analyzer requiring manual review",
    "action_needed": "investigate"
  },
  {
    "timestamp": 1767057111154.0,
    "timestamp_human": "2025-12-29T19:11:51.154347",
    "namespace": "log-analyzer",
    "pod": "log-analyzer-6579fdbfb-jzlq7",
    "container": "log-analyzer",
    "node": "node-1",
    "log_line": "await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)",
    "detected_severity": "ERROR",
    "signature": "await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)",
    "signature_hash": "0b5489ed",
    "source": "real",
    "root_cause": "unknown",
    "severity": "error",
    "component": "log_analyzer",
    "summary": "Log from log-analyzer requiring manual review",
    "action_needed": "investigate"
  },
  {
    "timestamp": 1767056653332.0,
    "timestamp_human": "2025-12-29T19:04:13.332249",
    "namespace": "log-analyzer",
    "pod": "log-analyzer-6579fdbfb-jzlq7",
    "container": "log-analyzer",
    "node": "node-1",
    "log_line": "await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)",
    "detected_severity": "ERROR",
    "signature": "await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)",
    "signature_hash": "0b5489ed",
    "source": "real",
    "root_cause": "unknown",
    "severity": "error",
    "component": "log_analyzer",
    "summary": "Log from log-analyzer requiring manual review",
    "action_needed": "investigate"
  },
  {
    "timestamp": 1767057111154.0,
    "timestamp_human": "2025-12-29T19:11:51.154340",
    "namespace": "log-analyzer",
    "pod": "log-analyzer-6579fdbfb-jzlq7",
    "container": "log-analyzer",
    "node": "node-1",
    "log_line": "File \"/usr/local/lib/python3.13/site-packages/starlette/middleware/exceptions.py\", line 63, in __call__",
    "detected_severity": "ERROR",
    "signature": "File \"/usr/local/lib/python3.13/site-packages/starlette/middleware/exceptions.py\", line 63, in __call__",
    "signature_hash": "6219d2d9",
    "source": "real",
    "root_cause": "exception_stacktrace",
    "severity": "error",
    "component": "log_analyzer_api",
    "summary": "Python exception stacktrace fragment from FastAPI exception middleware",
    "action_needed": "investigate"
  },
  {
    "timestamp": 1767056653332.0,
    "timestamp_human": "2025-12-29T19:04:13.332244",
    "namespace": "log-analyzer",
    "pod": "log-analyzer-6579fdbfb-jzlq7",
    "container": "log-analyzer",
    "node": "node-1",
    "log_line": "File \"/usr/local/lib/python3.13/site-packages/starlette/middleware/exceptions.py\", line 63, in __call__",
    "detected_severity": "ERROR",
    "signature": "File \"/usr/local/lib/python3.13/site-packages/starlette/middleware/exceptions.py\", line 63, in __call__",
    "signature_hash": "6219d2d9",
    "source": "real",
    "root_cause": "exception_stacktrace",
    "severity": "error",
    "component": "log_analyzer_api",
    "summary": "Python exception stacktrace fragment from FastAPI exception middleware",
    "action_needed": "investigate"
  },
  {
    "timestamp": 1766954816854.0,
    "timestamp_human": "2025-12-28T14:46:56.854759",
    "namespace": "log-analyzer",
    "pod": "log-analyzer-7669d66676-gvm8p",
    "container": "log-analyzer",
    "node": "node-1",
    "log_line": "httpx.ConnectError: All connection attempts failed",
    "detected_severity": "ERROR",
    "signature": "httpx.ConnectError: All connection attempts failed",
    "signature_hash": "850c9db1",
    "source": "real",
    "root_cause": "http_client_error",
    "severity": "error",
    "component": "log_analyzer_api",
    "summary": "HTTP client error when calling downstream service",
    "action_needed": "investigate"
  },
  {
    "timestamp": 1766954787605.0,
    "timestamp_human": "2025-12-28T14:46:27.605990",
    "namespace": "log-analyzer",
    "pod": "log-analyzer-7669d66676-gvm8p",
    "container": "log-analyzer",
    "node": "node-1",
    "log_line": "httpx.ConnectError: All connection attempts failed",
    "detected_severity": "ERROR",
    "signature": "httpx.ConnectError: All connection attempts failed",
    "signature_hash": "850c9db1",
    "source": "real",
    "root_cause": "http_client_error",
    "severity": "error",
    "component": "log_analyzer_api",
    "summary": "HTTP client error when calling downstream service",
    "action_needed": "investigate"
  },
  {
    "timestamp": 1766954816854.0,
    "timestamp_human": "2025-12-28T14:46:56.854756",
    "namespace": "log-analyzer",
    "pod": "log-analyzer-7669d66676-gvm8p",
    "container": "log-analyzer",
    "node": "node-1",
    "log_line": "File \"/usr/local/lib/python3.13/site-packages/httpx/_transports/default.py\", line 118, in map_httpcore_exceptions",
    "detected_severity": "ERROR",
    "signature": "File \"/usr/local/lib/python3.13/site-packages/httpx/_transports/default.py\", line 118, in map_httpcore_exceptions",
    "signature_hash": "f493b04b",
    "source": "real",
    "root_cause": "exception_stacktrace",
    "severity": "error",
    "component": "log_analyzer_api",
    "summary": "Python exception stacktrace fragment from FastAPI handler",
    "action_needed": "investigate"
  },
  {
    "timestamp": 1766954787605.0,
    "timestamp_human": "2025-12-28T14:46:27.605987",
    "namespace": "log-analyzer",
    "pod": "log-analyzer-7669d66676-gvm8p",
    "container": "log-analyzer",
    "node": "node-1",
    "log_line": "File \"/usr/local/lib/python3.13/site-packages/httpx/_transports/default.py\", line 118, in map_httpcore_exceptions",
    "detected_severity": "ERROR",
    "signature": "File \"/usr/local/lib/python3.13/site-packages/httpx/_transports/default.py\", line 118, in map_httpcore_exceptions",
    "signature_hash": "f493b04b",
    "source": "real",
    "root_cause": "exception_stacktrace",
    "severity": "error",
    "component": "log_analyzer_api",
    "summary": "Python exception stacktrace fragment from FastAPI handler",
    "action_needed": "investigate"
  },
  {
    "timestamp": 1766954816854.0,
    "timestamp_human": "2025-12-28T14:46:56.854750",
    "namespace": "log-analyzer",
    "pod": "log-analyzer-7669d66676-gvm8p",
    "container": "log-analyzer",
    "node": "node-1",
    "log_line": "with map_httpcore_exceptions():",
    "detected_severity": "ERROR",
    "signature": "with map_httpcore_exceptions():",
    "signature_hash": "98e23d61",
    "source": "real",
    "root_cause": "unknown",
    "severity": "error",
    "component": "log_analyzer",
    "summary": "Log from log-analyzer requiring manual review",
    "action_needed": "investigate"
  },
  {
    "timestamp": 1767057238262.0,
    "timestamp_human": "2025-12-29T19:13:58.262613",
    "namespace": "llm",
    "pod": "llama-cpp-968bcbbbd-bjrj5",
    "container": "llama-server",
    "node": "node-2",
    "log_line": "warning: consult docs/build.md for compilation instructions",
    "detected_severity": "WARN",
    "signature": "warning: consult docs/build.md for compilation instructions",
    "signature_hash": "e22fa811",
    "source": "real",
    "root_cause": "build_info_message",
    "severity": "info",
    "component": "llama_cpp",
    "summary": "Informational message about llama.cpp build documentation",
    "action_needed": "none"
  },
  {
    "timestamp": 1767050290439.0,
    "timestamp_human": "2025-12-29T17:18:10.439072",
    "namespace": "llm",
    "pod": "llama-cpp-5644f4579c-qnmvj",
    "container": "llama-server",
    "node": "node-2",
    "log_line": "warning: consult docs/build.md for compilation instructions",
    "detected_severity": "WARN",
    "signature": "warning: consult docs/build.md for compilation instructions",
    "signature_hash": "e22fa811",
    "source": "real",
    "root_cause": "build_info_message",
    "severity": "info",
    "component": "llama_cpp",
    "summary": "Informational message about llama.cpp build documentation",
    "action_needed": "none"
  },
  {
    "timestamp": 1767057238262.0,
    "timestamp_human": "2025-12-29T19:13:58.262609",
    "namespace": "llm",
    "pod": "llama-cpp-968bcbbbd-bjrj5",
    "container": "llama-server",
    "node": "node-2",
    "log_line": "warning: one possible reason is that llama.cpp was compiled without GPU support",
    "detected_severity": "WARN",
    "signature": "warning: one possible reason is that llama.cpp was compiled without GPU support",
    "signature_hash": "97a76ca0",
    "source": "real",
    "root_cause": "no_gpu_acceleration",
    "severity": "info",
    "component": "llama_cpp",
    "summary": "llama.cpp running without GPU acceleration (expected for CPU-only deployment)",
    "action_needed": "none"
  },
  {
    "timestamp": 1767050290439.0,
    "timestamp_human": "2025-12-29T17:18:10.439068",
    "namespace": "llm",
    "pod": "llama-cpp-5644f4579c-qnmvj",
    "container": "llama-server",
    "node": "node-2",
    "log_line": "warning: one possible reason is that llama.cpp was compiled without GPU support",
    "detected_severity": "WARN",
    "signature": "warning: one possible reason is that llama.cpp was compiled without GPU support",
    "signature_hash": "97a76ca0",
    "source": "real",
    "root_cause": "no_gpu_acceleration",
    "severity": "info",
    "component": "llama_cpp",
    "summary": "llama.cpp running without GPU acceleration (expected for CPU-only deployment)",
    "action_needed": "none"
  },
  {
    "timestamp": 1767057238262.0,
    "timestamp_human": "2025-12-29T19:13:58.262605",
    "namespace": "llm",
    "pod": "llama-cpp-968bcbbbd-bjrj5",
    "container": "llama-server",
    "node": "node-2",
    "log_line": "warning: no usable GPU found, --gpu-layers option will be ignored",
    "detected_severity": "WARN",
    "signature": "warning: no usable GPU found, --gpu-layers option will be ignored",
    "signature_hash": "9ca226ae",
    "source": "real",
    "root_cause": "unknown",
    "severity": "warn",
    "component": "llm",
    "summary": "Log from llm requiring manual review",
    "action_needed": "investigate"
  },
  {
    "timestamp": 1767050290439.0,
    "timestamp_human": "2025-12-29T17:18:10.439067",
    "namespace": "llm",
    "pod": "llama-cpp-5644f4579c-qnmvj",
    "container": "llama-server",
    "node": "node-2",
    "log_line": "warning: no usable GPU found, --gpu-layers option will be ignored",
    "detected_severity": "WARN",
    "signature": "warning: no usable GPU found, --gpu-layers option will be ignored",
    "signature_hash": "9ca226ae",
    "source": "real",
    "root_cause": "unknown",
    "severity": "warn",
    "component": "llm",
    "summary": "Log from llm requiring manual review",
    "action_needed": "investigate"
  },
  {
    "timestamp": 1767057238262.0,
    "timestamp_human": "2025-12-29T19:13:58.262597",
    "namespace": "llm",
    "pod": "llama-cpp-968bcbbbd-bjrj5",
    "container": "llama-server",
    "node": "node-2",
    "log_line": "warn: LLAMA_ARG_HOST environment variable is set, but will be overwritten by command line argument --host",
    "detected_severity": "WARN",
    "signature": "warn: LLAMA_ARG_HOST environment variable is set, but will be overwritten by command line argument --host",
    "signature_hash": "3a1208e2",
    "source": "real",
    "root_cause": "config_override_warning",
    "severity": "warn",
    "component": "llama_cpp",
    "summary": "Environment variable overridden by command-line argument (benign config precedence)",
    "action_needed": "none"
  },
  {
    "timestamp": 1767050290439.0,
    "timestamp_human": "2025-12-29T17:18:10.439065",
    "namespace": "llm",
    "pod": "llama-cpp-5644f4579c-qnmvj",
    "container": "llama-server",
    "node": "node-2",
    "log_line": "warn: LLAMA_ARG_HOST environment variable is set, but will be overwritten by command line argument --host",
    "detected_severity": "WARN",
    "signature": "warn: LLAMA_ARG_HOST environment variable is set, but will be overwritten by command line argument --host",
    "signature_hash": "3a1208e2",
    "source": "real",
    "root_cause": "config_override_warning",
    "severity": "warn",
    "component": "llama_cpp",
    "summary": "Environment variable overridden by command-line argument (benign config precedence)",
    "action_needed": "none"
  },
  {
    "timestamp": 1766963860218.0,
    "timestamp_human": "2025-12-28T17:17:40.218081",
    "namespace": "llm",
    "pod": "llama-cpp-77c6884846-2rj47",
    "container": "llama-server",
    "node": "node-2",
    "log_line": "srv    send_error: task id = 755, error: request (3552 tokens) exceeds the available context size (2048 tokens), try increasing it",
    "detected_severity": "ERROR",
    "signature": "srv    send_error: task id = 755, error: request (3552 tokens) exceeds the available context size (2048 tokens), try increasing it",
    "signature_hash": "8b12aaaa",
    "source": "real",
    "root_cause": "context_size_exceeded",
    "severity": "error",
    "component": "llama_cpp",
    "summary": "LLM request exceeded configured context window size",
    "action_needed": "increase_context_size"
  },
  {
    "timestamp": 1766856599753.0,
    "timestamp_human": "2025-12-27T11:29:59.753564",
    "namespace": "llm",
    "pod": "llama-cpp-77c6884846-2rj47",
    "container": "llama-server",
    "node": "node-2",
    "log_line": "srv    send_error: task id = 5437, error: the request exceeds the available context size, try increasing it",
    "detected_severity": "ERROR",
    "signature": "srv    send_error: task id = 5437, error: the request exceeds the available context size, try increasing it",
    "signature_hash": "b6f579f4",
    "source": "real",
    "root_cause": "context_size_exceeded",
    "severity": "error",
    "component": "llama_cpp",
    "summary": "LLM request exceeded configured context window size",
    "action_needed": "increase_context_size"
  },
  {
    "timestamp": 1766798660270.0,
    "timestamp_human": "2025-12-26T19:24:20.270664",
    "namespace": "llm",
    "pod": "llama-cpp-77c6884846-2rj47",
    "container": "llama-server",
    "node": "node-2",
    "log_line": "srv    send_error: task id = 5081, error: the request exceeds the available context size, try increasing it",
    "detected_severity": "ERROR",
    "signature": "srv    send_error: task id = 5081, error: the request exceeds the available context size, try increasing it",
    "signature_hash": "186c6e9e",
    "source": "real",
    "root_cause": "context_size_exceeded",
    "severity": "error",
    "component": "llama_cpp",
    "summary": "LLM request exceeded configured context window size",
    "action_needed": "increase_context_size"
  },
  {
    "timestamp": 1766797990083.0,
    "timestamp_human": "2025-12-26T19:13:10.083556",
    "namespace": "llm",
    "pod": "llama-cpp-77c6884846-2rj47",
    "container": "llama-server",
    "node": "node-2",
    "log_line": "srv    send_error: task id = 5078, error: the request exceeds the available context size, try increasing it",
    "detected_severity": "ERROR",
    "signature": "srv    send_error: task id = 5078, error: the request exceeds the available context size, try increasing it",
    "signature_hash": "ff820585",
    "source": "real",
    "root_cause": "context_size_exceeded",
    "severity": "error",
    "component": "llama_cpp",
    "summary": "LLM request exceeded configured context window size",
    "action_needed": "increase_context_size"
  },
  {
    "timestamp": 1766773939620.0,
    "timestamp_human": "2025-12-26T12:32:19.620520",
    "namespace": "llm",
    "pod": "llama-cpp-77c6884846-2rj47",
    "container": "llama-server",
    "node": "node-2",
    "log_line": "srv    send_error: task id = 1808, error: the request exceeds the available context size, try increasing it",
    "detected_severity": "ERROR",
    "signature": "srv    send_error: task id = 1808, error: the request exceeds the available context size, try increasing it",
    "signature_hash": "28439804",
    "source": "real",
    "root_cause": "context_size_exceeded",
    "severity": "error",
    "component": "llama_cpp",
    "summary": "LLM request exceeded configured context window size",
    "action_needed": "increase_context_size"
  },
  {
    "timestamp": 1766773935305.0,
    "timestamp_human": "2025-12-26T12:32:15.305556",
    "namespace": "llm",
    "pod": "llama-cpp-77c6884846-2rj47",
    "container": "llama-server",
    "node": "node-2",
    "log_line": "srv    send_error: task id = 1805, error: the request exceeds the available context size, try increasing it",
    "detected_severity": "ERROR",
    "signature": "srv    send_error: task id = 1805, error: the request exceeds the available context size, try increasing it",
    "signature_hash": "b820187b",
    "source": "real",
    "root_cause": "context_size_exceeded",
    "severity": "error",
    "component": "llama_cpp",
    "summary": "LLM request exceeded configured context window size",
    "action_needed": "increase_context_size"
  },
  {
    "timestamp": 1766773904160.0,
    "timestamp_human": "2025-12-26T12:31:44.160893",
    "namespace": "llm",
    "pod": "llama-cpp-77c6884846-2rj47",
    "container": "llama-server",
    "node": "node-2",
    "log_line": "srv    send_error: task id = 1802, error: the request exceeds the available context size, try increasing it",
    "detected_severity": "ERROR",
    "signature": "srv    send_error: task id = 1802, error: the request exceeds the available context size, try increasing it",
    "signature_hash": "f276bfde",
    "source": "real",
    "root_cause": "context_size_exceeded",
    "severity": "error",
    "component": "llama_cpp",
    "summary": "LLM request exceeded configured context window size",
    "action_needed": "increase_context_size"
  },
  {
    "timestamp": 1766773899740.0,
    "timestamp_human": "2025-12-26T12:31:39.740269",
    "namespace": "llm",
    "pod": "llama-cpp-77c6884846-2rj47",
    "container": "llama-server",
    "node": "node-2",
    "log_line": "srv    send_error: task id = 1799, error: the request exceeds the available context size, try increasing it",
    "detected_severity": "ERROR",
    "signature": "srv    send_error: task id = 1799, error: the request exceeds the available context size, try increasing it",
    "signature_hash": "14dda18a",
    "source": "real",
    "root_cause": "context_size_exceeded",
    "severity": "error",
    "component": "llama_cpp",
    "summary": "LLM request exceeded configured context window size",
    "action_needed": "increase_context_size"
  },
  {
    "timestamp": 1767057111122.0,
    "timestamp_human": "2025-12-29T19:11:51.122167",
    "namespace": "llm",
    "pod": "llama-cpp-5644f4579c-qnmvj",
    "container": "llama-server",
    "node": "node-2",
    "log_line": "srv    send_error: task id = 758, error: request (2288 tokens) exceeds the available context size (2048 tokens), try increasing it",
    "detected_severity": "ERROR",
    "signature": "srv    send_error: task id = 758, error: request (2288 tokens) exceeds the available context size (2048 tokens), try increasing it",
    "signature_hash": "913a6424",
    "source": "real",
    "root_cause": "context_size_exceeded",
    "severity": "error",
    "component": "llama_cpp",
    "summary": "LLM request exceeded configured context window size",
    "action_needed": "increase_context_size"
  },
  {
    "timestamp": 1767056653293.0,
    "timestamp_human": "2025-12-29T19:04:13.293069",
    "namespace": "llm",
    "pod": "llama-cpp-5644f4579c-qnmvj",
    "container": "llama-server",
    "node": "node-2",
    "log_line": "srv    send_error: task id = 302, error: request (2980 tokens) exceeds the available context size (2048 tokens), try increasing it",
    "detected_severity": "ERROR",
    "signature": "srv    send_error: task id = 302, error: request (2980 tokens) exceeds the available context size (2048 tokens), try increasing it",
    "signature_hash": "ec386623",
    "source": "real",
    "root_cause": "context_size_exceeded",
    "severity": "error",
    "component": "llama_cpp",
    "summary": "LLM request exceeded configured context window size",
    "action_needed": "increase_context_size"
  },
  {
    "timestamp": 1767120330116.0,
    "timestamp_human": "2025-12-30T12:45:30.116874",
    "namespace": "logging",
    "pod": "loki-0",
    "container": "loki",
    "node": "node-2",
    "log_line": "ts=2025-12-30T18:45:30.029765605Z caller=spanlogger.go:111 middleware=QueryShard.astMapperware org_id=fake user=fake caller=log.go:168 level=warn msg=\"failed mapping AST\" err=\"context canceled\" query=\"{namespace=\\\"log-analyzer\\\"} |~ \\\"(?i)(error|warn|critical|exception|failed)\\\"\"",
    "detected_severity": "CRITICAL",
    "signature": "ts=<TIMESTAMP> caller=spanlogger.go:<PORT> middleware=QueryShard.astMapperware org_id=fake user=fake caller=log.go:<PORT> level=warn msg=\"failed mapping AST\" err=\"context canceled\" query=\"{namespace=\\\"log-analyzer\\\"} |~ \\\"(?i)(error|warn|critical|exception|failed)\\\"\"",
    "signature_hash": "bae93254",
    "source": "real",
    "root_cause": "query_canceled",
    "severity": "warn",
    "component": "loki",
    "summary": "Loki query canceled by client before completion",
    "action_needed": "none"
  },
  {
    "timestamp": 1767120330116.0,
    "timestamp_human": "2025-12-30T12:45:30.116870",
    "namespace": "logging",
    "pod": "loki-0",
    "container": "loki",
    "node": "node-2",
    "log_line": "ts=2025-12-30T18:45:30.029766794Z caller=spanlogger.go:111 middleware=QueryShard.astMapperware org_id=fake user=fake caller=log.go:168 level=warn msg=\"failed mapping AST\" err=\"context canceled\" query=\"{namespace=\\\"log-analyzer\\\"} |~ \\\"(?i)(error|warn|critical|exception|failed)\\\"\"",
    "detected_severity": "CRITICAL",
    "signature": "ts=<TIMESTAMP> caller=spanlogger.go:<PORT> middleware=QueryShard.astMapperware org_id=fake user=fake caller=log.go:<PORT> level=warn msg=\"failed mapping AST\" err=\"context canceled\" query=\"{namespace=\\\"log-analyzer\\\"} |~ \\\"(?i)(error|warn|critical|exception|failed)\\\"\"",
    "signature_hash": "bae93254",
    "source": "real",
    "root_cause": "query_canceled",
    "severity": "warn",
    "component": "loki",
    "summary": "Loki query canceled by client before completion",
    "action_needed": "none"
  },
  {
    "timestamp": 1767120330186.0,
    "timestamp_human": "2025-12-30T12:45:30.186753",
    "namespace": "logging",
    "pod": "loki-0",
    "container": "loki",
    "node": "node-2",
    "log_line": "level=error ts=2025-12-30T18:45:30.120814769Z caller=scheduler_processor.go:175 component=querier org_id=fake msg=\"error notifying scheduler about finished query\" err=EOF addr=10.244.1.10:9095",
    "detected_severity": "ERROR",
    "signature": "level=error ts=<TIMESTAMP> caller=scheduler_processor.go:<PORT> component=querier org_id=fake msg=\"error notifying scheduler about finished query\" err=EOF addr=<IP>:<PORT>",
    "signature_hash": "2fa33429",
    "source": "real",
    "root_cause": "scheduler_communication_error",
    "severity": "error",
    "component": "loki",
    "summary": "Loki querier lost connection to scheduler while reporting query completion",
    "action_needed": "monitor"
  },
  {
    "timestamp": 1767120330186.0,
    "timestamp_human": "2025-12-30T12:45:30.186718",
    "namespace": "logging",
    "pod": "loki-0",
    "container": "loki",
    "node": "node-2",
    "log_line": "level=error ts=2025-12-30T18:45:30.119122586Z caller=scheduler_processor.go:175 component=querier org_id=fake msg=\"error notifying scheduler about finished query\" err=EOF addr=10.244.1.10:9095",
    "detected_severity": "ERROR",
    "signature": "level=error ts=<TIMESTAMP> caller=scheduler_processor.go:<PORT> component=querier org_id=fake msg=\"error notifying scheduler about finished query\" err=EOF addr=<IP>:<PORT>",
    "signature_hash": "2fa33429",
    "source": "real",
    "root_cause": "scheduler_communication_error",
    "severity": "error",
    "component": "loki",
    "summary": "Loki querier lost connection to scheduler while reporting query completion",
    "action_needed": "monitor"
  },
  {
    "timestamp": 1767120330186.0,
    "timestamp_human": "2025-12-30T12:45:30.186738",
    "namespace": "logging",
    "pod": "loki-0",
    "container": "loki",
    "node": "node-2",
    "log_line": "level=error ts=2025-12-30T18:45:30.120150676Z caller=scheduler_processor.go:111 component=querier msg=\"error processing requests from scheduler\" err=\"rpc error: code = Canceled desc = context canceled\" addr=10.244.1.10:9095",
    "detected_severity": "ERROR",
    "signature": "level=error ts=<TIMESTAMP> caller=scheduler_processor.go:<PORT> component=querier msg=\"error processing requests from scheduler\" err=\"rpc error: code = Canceled desc = context canceled\" addr=<IP>:<PORT>",
    "signature_hash": "7ad3a119",
    "source": "real",
    "root_cause": "scheduler_context_canceled",
    "severity": "error",
    "component": "loki",
    "summary": "Loki querier stopped processing requests due to context cancellation",
    "action_needed": "monitor"
  },
  {
    "timestamp": 1767120330186.0,
    "timestamp_human": "2025-12-30T12:45:30.186727",
    "namespace": "logging",
    "pod": "loki-0",
    "container": "loki",
    "node": "node-2",
    "log_line": "level=error ts=2025-12-30T18:45:30.119150478Z caller=scheduler_processor.go:111 component=querier msg=\"error processing requests from scheduler\" err=\"rpc error: code = Canceled desc = context canceled\" addr=10.244.1.10:9095",
    "detected_severity": "ERROR",
    "signature": "level=error ts=<TIMESTAMP> caller=scheduler_processor.go:<PORT> component=querier msg=\"error processing requests from scheduler\" err=\"rpc error: code = Canceled desc = context canceled\" addr=<IP>:<PORT>",
    "signature_hash": "7ad3a119",
    "source": "real",
    "root_cause": "scheduler_context_canceled",
    "severity": "error",
    "component": "loki",
    "summary": "Loki querier stopped processing requests due to context cancellation",
    "action_needed": "monitor"
  },
  {
    "timestamp": 1767120330116.0,
    "timestamp_human": "2025-12-30T12:45:30.116900",
    "namespace": "logging",
    "pod": "loki-0",
    "container": "loki",
    "node": "node-2",
    "log_line": "level=error ts=2025-12-30T18:45:30.030022237Z caller=scheduler_processor.go:254 component=querier org_id=fake frontend=10.244.1.10:9095 msg=\"error notifying frontend about finished query\" err=\"rpc error: code = Canceled desc = context canceled\"",
    "detected_severity": "ERROR",
    "signature": "level=error ts=<TIMESTAMP> caller=scheduler_processor.go:<PORT> component=querier org_id=fake frontend=<IP>:<PORT> msg=\"error notifying frontend about finished query\" err=\"rpc error: code = Canceled desc = context canceled\"",
    "signature_hash": "59e2f155",
    "source": "real",
    "root_cause": "unknown",
    "severity": "error",
    "component": "logging",
    "summary": "Log from logging requiring manual review",
    "action_needed": "investigate"
  },
  {
    "timestamp": 1767120333204.0,
    "timestamp_human": "2025-12-30T12:45:33.204125",
    "namespace": "logging",
    "pod": "grafana-5cdb9b48b6-25jfs",
    "container": "grafana",
    "node": "node-1",
    "log_line": "logger=authn.service t=2025-12-30T12:45:33.203846556-06:00 level=warn msg=\"Failed to authenticate request\" client=auth.client.session error=\"user token not found\"",
    "detected_severity": "ERROR",
    "signature": "logger=authn.service t=<TIMESTAMP> level=warn msg=\"Failed to authenticate request\" client=auth.client.session error=\"user token not found\"",
    "signature_hash": "cc24a55d",
    "source": "real",
    "root_cause": "unknown",
    "severity": "error",
    "component": "logging",
    "summary": "Log from logging requiring manual review",
    "action_needed": "investigate"
  },
  {
    "timestamp": 1767120310244.0,
    "timestamp_human": "2025-12-30T12:45:10.244145",
    "namespace": "kube-system",
    "pod": "kube-controller-manager-node-1",
    "container": "kube-controller-manager",
    "node": "node-1",
    "log_line": "I1230 18:45:10.243882       1 garbagecollector.go:792] \"failed to discover some groups\" groups=\"map[\\\"metrics.k8s.io/v1beta1\\\":\\\"stale GroupVersion discovery: metrics.k8s.io/v1beta1\\\"]\"",
    "detected_severity": "ERROR",
    "signature": "I1230 18:<PORT>:<PORT>.243882       1 garbagecollector.go:<PORT>] \"failed to discover some groups\" groups=\"map[\\\"metrics.k8s.io/v1beta1\\\":\\\"stale GroupVersion discovery: metrics.k8s.io/v1beta1\\\"]\"",
    "signature_hash": "db050b36",
    "source": "real",
    "root_cause": "metrics_server_missing",
    "severity": "warn",
    "component": "kube_controller_manager",
    "summary": "Garbage collector cannot discover metrics API (metrics-server not installed)",
    "action_needed": "none"
  },
  {
    "timestamp": 1767120310180.0,
    "timestamp_human": "2025-12-30T12:45:10.180673",
    "namespace": "kube-system",
    "pod": "kube-controller-manager-node-1",
    "container": "kube-controller-manager",
    "node": "node-1",
    "log_line": "E1230 18:45:10.180357       1 resource_quota_controller.go:460] \"Error during resource discovery\" err=\"unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: stale GroupVersion discovery: metrics.k8s.io/v1beta1\" logger=\"UnhandledError\"",
    "detected_severity": "ERROR",
    "signature": "E1230 18:<PORT>:<PORT>.180357       1 resource_quota_controller.go:<PORT>] \"Error during resource discovery\" err=\"unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: stale GroupVersion discovery: metrics.k8s.io/v1beta1\" logger=\"UnhandledError\"",
    "signature_hash": "7dfe6fa0",
    "source": "real",
    "root_cause": "unknown",
    "severity": "error",
    "component": "kube_system",
    "summary": "Log from kube-system requiring manual review",
    "action_needed": "investigate"
  },
  {
    "timestamp": 1767120280219.0,
    "timestamp_human": "2025-12-30T12:44:40.219553",
    "namespace": "kube-system",
    "pod": "kube-controller-manager-node-1",
    "container": "kube-controller-manager",
    "node": "node-1",
    "log_line": "I1230 18:44:40.219315       1 garbagecollector.go:792] \"failed to discover some groups\" groups=\"map[\\\"metrics.k8s.io/v1beta1\\\":\\\"stale GroupVersion discovery: metrics.k8s.io/v1beta1\\\"]\"",
    "detected_severity": "ERROR",
    "signature": "I1230 18:<PORT>:<PORT>.219315       1 garbagecollector.go:<PORT>] \"failed to discover some groups\" groups=\"map[\\\"metrics.k8s.io/v1beta1\\\":\\\"stale GroupVersion discovery: metrics.k8s.io/v1beta1\\\"]\"",
    "signature_hash": "c32feafa",
    "source": "real",
    "root_cause": "metrics_server_missing",
    "severity": "warn",
    "component": "kube_controller_manager",
    "summary": "Garbage collector cannot discover metrics API (metrics-server not installed)",
    "action_needed": "none"
  },
  {
    "timestamp": 1767120280166.0,
    "timestamp_human": "2025-12-30T12:44:40.166289",
    "namespace": "kube-system",
    "pod": "kube-controller-manager-node-1",
    "container": "kube-controller-manager",
    "node": "node-1",
    "log_line": "E1230 18:44:40.165943       1 resource_quota_controller.go:460] \"Error during resource discovery\" err=\"unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: stale GroupVersion discovery: metrics.k8s.io/v1beta1\" logger=\"UnhandledError\"",
    "detected_severity": "ERROR",
    "signature": "E1230 18:<PORT>:<PORT>.165943       1 resource_quota_controller.go:<PORT>] \"Error during resource discovery\" err=\"unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: stale GroupVersion discovery: metrics.k8s.io/v1beta1\" logger=\"UnhandledError\"",
    "signature_hash": "64c283a1",
    "source": "real",
    "root_cause": "unknown",
    "severity": "error",
    "component": "kube_system",
    "summary": "Log from kube-system requiring manual review",
    "action_needed": "investigate"
  },
  {
    "timestamp": 1767120250196.0,
    "timestamp_human": "2025-12-30T12:44:10.196546",
    "namespace": "kube-system",
    "pod": "kube-controller-manager-node-1",
    "container": "kube-controller-manager",
    "node": "node-1",
    "log_line": "I1230 18:44:10.196298       1 garbagecollector.go:792] \"failed to discover some groups\" groups=\"map[\\\"metrics.k8s.io/v1beta1\\\":\\\"stale GroupVersion discovery: metrics.k8s.io/v1beta1\\\"]\"",
    "detected_severity": "ERROR",
    "signature": "I1230 18:<PORT>:<PORT>.196298       1 garbagecollector.go:<PORT>] \"failed to discover some groups\" groups=\"map[\\\"metrics.k8s.io/v1beta1\\\":\\\"stale GroupVersion discovery: metrics.k8s.io/v1beta1\\\"]\"",
    "signature_hash": "1aa8960c",
    "source": "real",
    "root_cause": "metrics_server_missing",
    "severity": "warn",
    "component": "kube_controller_manager",
    "summary": "Garbage collector cannot discover metrics API (metrics-server not installed)",
    "action_needed": "none"
  },
  {
    "timestamp": 1767120250152.0,
    "timestamp_human": "2025-12-30T12:44:10.152159",
    "namespace": "kube-system",
    "pod": "kube-controller-manager-node-1",
    "container": "kube-controller-manager",
    "node": "node-1",
    "log_line": "E1230 18:44:10.151872       1 resource_quota_controller.go:460] \"Error during resource discovery\" err=\"unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: stale GroupVersion discovery: metrics.k8s.io/v1beta1\" logger=\"UnhandledError\"",
    "detected_severity": "ERROR",
    "signature": "E1230 18:<PORT>:<PORT>.151872       1 resource_quota_controller.go:<PORT>] \"Error during resource discovery\" err=\"unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: stale GroupVersion discovery: metrics.k8s.io/v1beta1\" logger=\"UnhandledError\"",
    "signature_hash": "761cd9dd",
    "source": "real",
    "root_cause": "unknown",
    "severity": "error",
    "component": "kube_system",
    "summary": "Log from kube-system requiring manual review",
    "action_needed": "investigate"
  },
  {
    "timestamp": 1767120220173.0,
    "timestamp_human": "2025-12-30T12:43:40.173280",
    "namespace": "kube-system",
    "pod": "kube-controller-manager-node-1",
    "container": "kube-controller-manager",
    "node": "node-1",
    "log_line": "I1230 18:43:40.173013       1 garbagecollector.go:792] \"failed to discover some groups\" groups=\"map[\\\"metrics.k8s.io/v1beta1\\\":\\\"stale GroupVersion discovery: metrics.k8s.io/v1beta1\\\"]\"",
    "detected_severity": "ERROR",
    "signature": "I1230 18:<PORT>:<PORT>.173013       1 garbagecollector.go:<PORT>] \"failed to discover some groups\" groups=\"map[\\\"metrics.k8s.io/v1beta1\\\":\\\"stale GroupVersion discovery: metrics.k8s.io/v1beta1\\\"]\"",
    "signature_hash": "552b6715",
    "source": "real",
    "root_cause": "metrics_server_missing",
    "severity": "warn",
    "component": "kube_controller_manager",
    "summary": "Garbage collector cannot discover metrics API (metrics-server not installed)",
    "action_needed": "none"
  },
  {
    "timestamp": 1767120220135.0,
    "timestamp_human": "2025-12-30T12:43:40.135444",
    "namespace": "kube-system",
    "pod": "kube-controller-manager-node-1",
    "container": "kube-controller-manager",
    "node": "node-1",
    "log_line": "E1230 18:43:40.135129       1 resource_quota_controller.go:460] \"Error during resource discovery\" err=\"unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: stale GroupVersion discovery: metrics.k8s.io/v1beta1\" logger=\"UnhandledError\"",
    "detected_severity": "ERROR",
    "signature": "E1230 18:<PORT>:<PORT>.135129       1 resource_quota_controller.go:<PORT>] \"Error during resource discovery\" err=\"unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: stale GroupVersion discovery: metrics.k8s.io/v1beta1\" logger=\"UnhandledError\"",
    "signature_hash": "9445bfc9",
    "source": "real",
    "root_cause": "unknown",
    "severity": "error",
    "component": "kube_system",
    "summary": "Log from kube-system requiring manual review",
    "action_needed": "investigate"
  },
  {
    "timestamp": 1767120190151.0,
    "timestamp_human": "2025-12-30T12:43:10.151262",
    "namespace": "kube-system",
    "pod": "kube-controller-manager-node-1",
    "container": "kube-controller-manager",
    "node": "node-1",
    "log_line": "I1230 18:43:10.150951       1 garbagecollector.go:792] \"failed to discover some groups\" groups=\"map[\\\"metrics.k8s.io/v1beta1\\\":\\\"stale GroupVersion discovery: metrics.k8s.io/v1beta1\\\"]\"",
    "detected_severity": "ERROR",
    "signature": "I1230 18:<PORT>:<PORT>.150951       1 garbagecollector.go:<PORT>] \"failed to discover some groups\" groups=\"map[\\\"metrics.k8s.io/v1beta1\\\":\\\"stale GroupVersion discovery: metrics.k8s.io/v1beta1\\\"]\"",
    "signature_hash": "faf781d4",
    "source": "real",
    "root_cause": "metrics_server_missing",
    "severity": "warn",
    "component": "kube_controller_manager",
    "summary": "Garbage collector cannot discover metrics API (metrics-server not installed)",
    "action_needed": "none"
  },
  {
    "timestamp": 1767120190119.0,
    "timestamp_human": "2025-12-30T12:43:10.119085",
    "namespace": "kube-system",
    "pod": "kube-controller-manager-node-1",
    "container": "kube-controller-manager",
    "node": "node-1",
    "log_line": "E1230 18:43:10.118804       1 resource_quota_controller.go:460] \"Error during resource discovery\" err=\"unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: stale GroupVersion discovery: metrics.k8s.io/v1beta1\" logger=\"UnhandledError\"",
    "detected_severity": "ERROR",
    "signature": "E1230 18:<PORT>:<PORT>.118804       1 resource_quota_controller.go:<PORT>] \"Error during resource discovery\" err=\"unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: stale GroupVersion discovery: metrics.k8s.io/v1beta1\" logger=\"UnhandledError\"",
    "signature_hash": "7023616d",
    "source": "real",
    "root_cause": "unknown",
    "severity": "error",
    "component": "kube_system",
    "summary": "Log from kube-system requiring manual review",
    "action_needed": "investigate"
  },
  {
    "timestamp": 1767120160124.0,
    "timestamp_human": "2025-12-30T12:42:40.124163",
    "namespace": "kube-system",
    "pod": "kube-controller-manager-node-1",
    "container": "kube-controller-manager",
    "node": "node-1",
    "log_line": "I1230 18:42:40.123949       1 garbagecollector.go:792] \"failed to discover some groups\" groups=\"map[\\\"metrics.k8s.io/v1beta1\\\":\\\"stale GroupVersion discovery: metrics.k8s.io/v1beta1\\\"]\"",
    "detected_severity": "ERROR",
    "signature": "I1230 18:<PORT>:<PORT>.123949       1 garbagecollector.go:<PORT>] \"failed to discover some groups\" groups=\"map[\\\"metrics.k8s.io/v1beta1\\\":\\\"stale GroupVersion discovery: metrics.k8s.io/v1beta1\\\"]\"",
    "signature_hash": "c4b8284d",
    "source": "real",
    "root_cause": "metrics_server_missing",
    "severity": "warn",
    "component": "kube_controller_manager",
    "summary": "Garbage collector cannot discover metrics API (metrics-server not installed)",
    "action_needed": "none"
  },
  {
    "timestamp": 1767120160102.0,
    "timestamp_human": "2025-12-30T12:42:40.102869",
    "namespace": "kube-system",
    "pod": "kube-controller-manager-node-1",
    "container": "kube-controller-manager",
    "node": "node-1",
    "log_line": "E1230 18:42:40.102568       1 resource_quota_controller.go:460] \"Error during resource discovery\" err=\"unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: stale GroupVersion discovery: metrics.k8s.io/v1beta1\" logger=\"UnhandledError\"",
    "detected_severity": "ERROR",
    "signature": "E1230 18:<PORT>:<PORT>.102568       1 resource_quota_controller.go:<PORT>] \"Error during resource discovery\" err=\"unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: stale GroupVersion discovery: metrics.k8s.io/v1beta1\" logger=\"UnhandledError\"",
    "signature_hash": "af32fc92",
    "source": "real",
    "root_cause": "unknown",
    "severity": "error",
    "component": "kube_system",
    "summary": "Log from kube-system requiring manual review",
    "action_needed": "investigate"
  },
  {
    "timestamp": 1767120130100.0,
    "timestamp_human": "2025-12-30T12:42:10.100356",
    "namespace": "kube-system",
    "pod": "kube-controller-manager-node-1",
    "container": "kube-controller-manager",
    "node": "node-1",
    "log_line": "I1230 18:42:10.100284       1 garbagecollector.go:792] \"failed to discover some groups\" groups=\"map[\\\"metrics.k8s.io/v1beta1\\\":\\\"stale GroupVersion discovery: metrics.k8s.io/v1beta1\\\"]\"",
    "detected_severity": "ERROR",
    "signature": "I1230 18:<PORT>:<PORT>.100284       1 garbagecollector.go:<PORT>] \"failed to discover some groups\" groups=\"map[\\\"metrics.k8s.io/v1beta1\\\":\\\"stale GroupVersion discovery: metrics.k8s.io/v1beta1\\\"]\"",
    "signature_hash": "f615146a",
    "source": "real",
    "root_cause": "metrics_server_missing",
    "severity": "warn",
    "component": "kube_controller_manager",
    "summary": "Garbage collector cannot discover metrics API (metrics-server not installed)",
    "action_needed": "none"
  },
  {
    "timestamp": 1767120130090.0,
    "timestamp_human": "2025-12-30T12:42:10.090420",
    "namespace": "kube-system",
    "pod": "kube-controller-manager-node-1",
    "container": "kube-controller-manager",
    "node": "node-1",
    "log_line": "E1230 18:42:10.090324       1 resource_quota_controller.go:460] \"Error during resource discovery\" err=\"unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: stale GroupVersion discovery: metrics.k8s.io/v1beta1\" logger=\"UnhandledError\"",
    "detected_severity": "ERROR",
    "signature": "E1230 18:<PORT>:<PORT>.090324       1 resource_quota_controller.go:<PORT>] \"Error during resource discovery\" err=\"unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: stale GroupVersion discovery: metrics.k8s.io/v1beta1\" logger=\"UnhandledError\"",
    "signature_hash": "f52e1e16",
    "source": "real",
    "root_cause": "unknown",
    "severity": "error",
    "component": "kube_system",
    "summary": "Log from kube-system requiring manual review",
    "action_needed": "investigate"
  },
  {
    "timestamp": 1767120100094.0,
    "timestamp_human": "2025-12-30T12:41:40.094955",
    "namespace": "kube-system",
    "pod": "kube-controller-manager-node-1",
    "container": "kube-controller-manager",
    "node": "node-1",
    "log_line": "I1230 18:41:40.094667       1 garbagecollector.go:792] \"failed to discover some groups\" groups=\"map[\\\"metrics.k8s.io/v1beta1\\\":\\\"stale GroupVersion discovery: metrics.k8s.io/v1beta1\\\"]\"",
    "detected_severity": "ERROR",
    "signature": "I1230 18:<PORT>:<PORT>.094667       1 garbagecollector.go:<PORT>] \"failed to discover some groups\" groups=\"map[\\\"metrics.k8s.io/v1beta1\\\":\\\"stale GroupVersion discovery: metrics.k8s.io/v1beta1\\\"]\"",
    "signature_hash": "eafd23d5",
    "source": "real",
    "root_cause": "metrics_server_missing",
    "severity": "warn",
    "component": "kube_controller_manager",
    "summary": "Garbage collector cannot discover metrics API (metrics-server not installed)",
    "action_needed": "none"
  },
  {
    "timestamp": 1767120100075.0,
    "timestamp_human": "2025-12-30T12:41:40.075375",
    "namespace": "kube-system",
    "pod": "kube-controller-manager-node-1",
    "container": "kube-controller-manager",
    "node": "node-1",
    "log_line": "E1230 18:41:40.075081       1 resource_quota_controller.go:460] \"Error during resource discovery\" err=\"unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: stale GroupVersion discovery: metrics.k8s.io/v1beta1\" logger=\"UnhandledError\"",
    "detected_severity": "ERROR",
    "signature": "E1230 18:<PORT>:<PORT>.075081       1 resource_quota_controller.go:<PORT>] \"Error during resource discovery\" err=\"unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: stale GroupVersion discovery: metrics.k8s.io/v1beta1\" logger=\"UnhandledError\"",
    "signature_hash": "6952ba24",
    "source": "real",
    "root_cause": "unknown",
    "severity": "error",
    "component": "kube_system",
    "summary": "Log from kube-system requiring manual review",
    "action_needed": "investigate"
  },
  {
    "timestamp": 1767120070063.0,
    "timestamp_human": "2025-12-30T12:41:10.063422",
    "namespace": "kube-system",
    "pod": "kube-controller-manager-node-1",
    "container": "kube-controller-manager",
    "node": "node-1",
    "log_line": "I1230 18:41:10.063348       1 garbagecollector.go:792] \"failed to discover some groups\" groups=\"map[\\\"metrics.k8s.io/v1beta1\\\":\\\"stale GroupVersion discovery: metrics.k8s.io/v1beta1\\\"]\"",
    "detected_severity": "ERROR",
    "signature": "I1230 18:<PORT>:<PORT>.063348       1 garbagecollector.go:<PORT>] \"failed to discover some groups\" groups=\"map[\\\"metrics.k8s.io/v1beta1\\\":\\\"stale GroupVersion discovery: metrics.k8s.io/v1beta1\\\"]\"",
    "signature_hash": "9df3a046",
    "source": "real",
    "root_cause": "metrics_server_missing",
    "severity": "warn",
    "component": "kube_controller_manager",
    "summary": "Garbage collector cannot discover metrics API (metrics-server not installed)",
    "action_needed": "none"
  },
  {
    "timestamp": 1767120070061.0,
    "timestamp_human": "2025-12-30T12:41:10.061329",
    "namespace": "kube-system",
    "pod": "kube-controller-manager-node-1",
    "container": "kube-controller-manager",
    "node": "node-1",
    "log_line": "E1230 18:41:10.061227       1 resource_quota_controller.go:460] \"Error during resource discovery\" err=\"unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: stale GroupVersion discovery: metrics.k8s.io/v1beta1\" logger=\"UnhandledError\"",
    "detected_severity": "ERROR",
    "signature": "E1230 18:<PORT>:<PORT>.061227       1 resource_quota_controller.go:<PORT>] \"Error during resource discovery\" err=\"unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: stale GroupVersion discovery: metrics.k8s.io/v1beta1\" logger=\"UnhandledError\"",
    "signature_hash": "081e8f4b",
    "source": "real",
    "root_cause": "unknown",
    "severity": "error",
    "component": "kube_system",
    "summary": "Log from kube-system requiring manual review",
    "action_needed": "investigate"
  },
  {
    "timestamp": 1767120289330.0,
    "timestamp_human": "2025-12-30T12:44:49.330709",
    "namespace": "kube-system",
    "pod": "kube-apiserver-node-1",
    "container": "kube-apiserver",
    "node": "node-1",
    "log_line": "> logger=\"UnhandledError\"",
    "detected_severity": "ERROR",
    "signature": "> logger=\"UnhandledError\"",
    "signature_hash": "fb08c8a5",
    "source": "real",
    "root_cause": "unknown",
    "severity": "error",
    "component": "kube_system",
    "summary": "Log from kube-system requiring manual review",
    "action_needed": "investigate"
  },
  {
    "timestamp": 1767120288330.0,
    "timestamp_human": "2025-12-30T12:44:48.330063",
    "namespace": "kube-system",
    "pod": "kube-apiserver-node-1",
    "container": "kube-apiserver",
    "node": "node-1",
    "log_line": "> logger=\"UnhandledError\"",
    "detected_severity": "ERROR",
    "signature": "> logger=\"UnhandledError\"",
    "signature_hash": "fb08c8a5",
    "source": "real",
    "root_cause": "unknown",
    "severity": "error",
    "component": "kube_system",
    "summary": "Log from kube-system requiring manual review",
    "action_needed": "investigate"
  },
  {
    "timestamp": 1767120107047.0,
    "timestamp_human": "2025-12-30T12:41:47.047701",
    "namespace": "flux-system",
    "pod": "helm-controller-74988df57b-jbp6h",
    "container": "manager",
    "node": "node-2",
    "log_line": "{\"level\":\"info\",\"ts\":\"2025-12-30T18:41:47.047Z\",\"msg\":\"HelmChart 'flux-system/monitoring-prometheus' is not ready: invalid chart reference: failed to get chart version for remote reference: no chart name found\",\"controller\":\"helmrelease\",\"controllerGroup\":\"helm.toolkit.fluxcd.io\",\"controllerKind\":\"HelmRelease\",\"HelmRelease\":{\"name\":\"prometheus\",\"namespace\":\"monitoring\"},\"namespace\":\"monitoring\",\"name\":\"prometheus\",\"reconcileID\":\"e60c18e4-8f6c-4ca0-82c9-04984923fd89\"}",
    "detected_severity": "ERROR",
    "signature": "{\"level\":\"info\",\"ts\":\"<TIMESTAMP>\",\"msg\":\"HelmChart 'flux-system/monitoring-prometheus' is not ready: invalid chart reference: failed to get chart version for remote reference: no chart name found\",\"controller\":\"helmrelease\",\"controllerGroup\":\"helm.toolkit.fluxcd.io\",\"controllerKind\":\"HelmRelease\",\"HelmRelease\":{\"name\":\"prometheus\",\"namespace\":\"monitoring\"},\"namespace\":\"monitoring\",\"name\":\"prometheus\",\"reconcileID\":\"<UUID>\"}",
    "signature_hash": "0d4be2d4",
    "source": "real",
    "root_cause": "helm_chart_invalid_reference",
    "severity": "error",
    "component": "flux_helm_controller",
    "summary": "Flux cannot find chart name in HelmChart resource configuration",
    "action_needed": "fix_helm_chart_spec"
  },
  {
    "timestamp": 1767120078363.0,
    "timestamp_human": "2025-12-30T12:41:18.363365",
    "namespace": "flux-system",
    "pod": "helm-controller-74988df57b-jbp6h",
    "container": "manager",
    "node": "node-2",
    "log_line": "{\"level\":\"info\",\"ts\":\"2025-12-30T18:41:18.363Z\",\"msg\":\"HelmChart 'flux-system/monitoring-prometheus' is not ready: invalid chart reference: failed to get chart version for remote reference: no chart name found\",\"controller\":\"helmrelease\",\"controllerGroup\":\"helm.toolkit.fluxcd.io\",\"controllerKind\":\"HelmRelease\",\"HelmRelease\":{\"name\":\"prometheus\",\"namespace\":\"monitoring\"},\"namespace\":\"monitoring\",\"name\":\"prometheus\",\"reconcileID\":\"8d6e3cf1-d004-4b14-be99-99045547131a\"}",
    "detected_severity": "ERROR",
    "signature": "{\"level\":\"info\",\"ts\":\"<TIMESTAMP>\",\"msg\":\"HelmChart 'flux-system/monitoring-prometheus' is not ready: invalid chart reference: failed to get chart version for remote reference: no chart name found\",\"controller\":\"helmrelease\",\"controllerGroup\":\"helm.toolkit.fluxcd.io\",\"controllerKind\":\"HelmRelease\",\"HelmRelease\":{\"name\":\"prometheus\",\"namespace\":\"monitoring\"},\"namespace\":\"monitoring\",\"name\":\"prometheus\",\"reconcileID\":\"8d6e3cf1-d004-4b14-be99-<TIMESTAMP>a\"}",
    "signature_hash": "21f5392b",
    "source": "real",
    "root_cause": "helm_chart_invalid_reference",
    "severity": "error",
    "component": "flux_helm_controller",
    "summary": "Flux cannot find chart name in HelmChart resource configuration",
    "action_needed": "fix_helm_chart_spec"
  },
  {
    "timestamp": 1767038574843.0,
    "timestamp_human": "2025-12-29T14:02:54.843328",
    "namespace": "flux-system",
    "pod": "helm-controller-74988df57b-jbp6h",
    "container": "manager",
    "node": "node-2",
    "log_line": "{\"level\":\"info\",\"ts\":\"2025-12-29T20:02:54.843Z\",\"msg\":\"release is in a failed state\",\"controller\":\"helmrelease\",\"controllerGroup\":\"helm.toolkit.fluxcd.io\",\"controllerKind\":\"HelmRelease\",\"HelmRelease\":{\"name\":\"tempo\",\"namespace\":\"logging\"},\"namespace\":\"logging\",\"name\":\"tempo\",\"reconcileID\":\"d8a9b4fc-b870-444a-8ade-4ee639d130c3\"}",
    "detected_severity": "ERROR",
    "signature": "{\"level\":\"info\",\"ts\":\"<TIMESTAMP>\",\"msg\":\"release is in a failed state\",\"controller\":\"helmrelease\",\"controllerGroup\":\"helm.toolkit.fluxcd.io\",\"controllerKind\":\"HelmRelease\",\"HelmRelease\":{\"name\":\"tempo\",\"namespace\":\"logging\"},\"namespace\":\"logging\",\"name\":\"tempo\",\"reconcileID\":\"<UUID>\"}",
    "signature_hash": "d12338c5",
    "source": "real",
    "root_cause": "helm_release_failed",
    "severity": "error",
    "component": "flux_helm_controller",
    "summary": "Helm release for Tempo is in failed state",
    "action_needed": "check_helm_release"
  },
  {
    "timestamp": 1767038406548.0,
    "timestamp_human": "2025-12-29T14:00:06.548313",
    "namespace": "flux-system",
    "pod": "helm-controller-74988df57b-jbp6h",
    "container": "manager",
    "node": "node-2",
    "log_line": "{\"level\":\"info\",\"ts\":\"2025-12-29T20:00:06.548Z\",\"msg\":\"release is in a failed state\",\"controller\":\"helmrelease\",\"controllerGroup\":\"helm.toolkit.fluxcd.io\",\"controllerKind\":\"HelmRelease\",\"HelmRelease\":{\"name\":\"tempo\",\"namespace\":\"logging\"},\"namespace\":\"logging\",\"name\":\"tempo\",\"reconcileID\":\"28949acd-3843-47d8-a04e-4334afe61a7b\"}",
    "detected_severity": "ERROR",
    "signature": "{\"level\":\"info\",\"ts\":\"<TIMESTAMP>\",\"msg\":\"release is in a failed state\",\"controller\":\"helmrelease\",\"controllerGroup\":\"helm.toolkit.fluxcd.io\",\"controllerKind\":\"HelmRelease\",\"HelmRelease\":{\"name\":\"tempo\",\"namespace\":\"logging\"},\"namespace\":\"logging\",\"name\":\"tempo\",\"reconcileID\":\"<UUID>\"}",
    "signature_hash": "d12338c5",
    "source": "real",
    "root_cause": "helm_release_failed",
    "severity": "error",
    "component": "flux_helm_controller",
    "summary": "Helm release for Tempo is in failed state",
    "action_needed": "check_helm_release"
  },
  {
    "timestamp": 1767037346891.0,
    "timestamp_human": "2025-12-29T13:42:26.891165",
    "namespace": "flux-system",
    "pod": "helm-controller-74988df57b-jbp6h",
    "container": "manager",
    "node": "node-2",
    "log_line": "{\"level\":\"info\",\"ts\":\"2025-12-29T19:42:26.890Z\",\"msg\":\"release is in a failed state\",\"controller\":\"helmrelease\",\"controllerGroup\":\"helm.toolkit.fluxcd.io\",\"controllerKind\":\"HelmRelease\",\"HelmRelease\":{\"name\":\"grafana\",\"namespace\":\"logging\"},\"namespace\":\"logging\",\"name\":\"grafana\",\"reconcileID\":\"79e92eb4-64ff-40d0-a973-702126c278e0\"}",
    "detected_severity": "ERROR",
    "signature": "{\"level\":\"info\",\"ts\":\"<TIMESTAMP>\",\"msg\":\"release is in a failed state\",\"controller\":\"helmrelease\",\"controllerGroup\":\"helm.toolkit.fluxcd.io\",\"controllerKind\":\"HelmRelease\",\"HelmRelease\":{\"name\":\"grafana\",\"namespace\":\"logging\"},\"namespace\":\"logging\",\"name\":\"grafana\",\"reconcileID\":\"<UUID>\"}",
    "signature_hash": "30e70a41",
    "source": "real",
    "root_cause": "helm_release_failed",
    "severity": "error",
    "component": "flux_helm_controller",
    "summary": "Helm release is in failed state",
    "action_needed": "check_helm_release"
  },
  {
    "timestamp": 1767037346761.0,
    "timestamp_human": "2025-12-29T13:42:26.761508",
    "namespace": "flux-system",
    "pod": "helm-controller-74988df57b-jbp6h",
    "container": "manager",
    "node": "node-2",
    "log_line": "{\"level\":\"info\",\"ts\":\"2025-12-29T19:42:26.761Z\",\"msg\":\"release is in a failed state\",\"controller\":\"helmrelease\",\"controllerGroup\":\"helm.toolkit.fluxcd.io\",\"controllerKind\":\"HelmRelease\",\"HelmRelease\":{\"name\":\"grafana\",\"namespace\":\"logging\"},\"namespace\":\"logging\",\"name\":\"grafana\",\"reconcileID\":\"e79228e1-bd08-48eb-9019-7b7d00b09697\"}",
    "detected_severity": "ERROR",
    "signature": "{\"level\":\"info\",\"ts\":\"<TIMESTAMP>\",\"msg\":\"release is in a failed state\",\"controller\":\"helmrelease\",\"controllerGroup\":\"helm.toolkit.fluxcd.io\",\"controllerKind\":\"HelmRelease\",\"HelmRelease\":{\"name\":\"grafana\",\"namespace\":\"logging\"},\"namespace\":\"logging\",\"name\":\"grafana\",\"reconcileID\":\"<UUID>\"}",
    "signature_hash": "30e70a41",
    "source": "real",
    "root_cause": "helm_release_failed",
    "severity": "error",
    "component": "flux_helm_controller",
    "summary": "Helm release is in failed state",
    "action_needed": "check_helm_release"
  },
  {
    "timestamp": 1767120049371.0,
    "timestamp_human": "2025-12-30T12:40:49.371182",
    "namespace": "flux-system",
    "pod": "source-controller-56c7f45479-5c7s2",
    "container": "manager",
    "node": "node-2",
    "log_line": "{\"level\":\"error\",\"ts\":\"2025-12-30T18:40:49.370Z\",\"msg\":\"reconciliation stalled\",\"controller\":\"helmchart\",\"controllerGroup\":\"source.toolkit.fluxcd.io\",\"controllerKind\":\"HelmChart\",\"HelmChart\":{\"name\":\"monitoring-prometheus\",\"namespace\":\"flux-system\"},\"namespace\":\"flux-system\",\"name\":\"monitoring-prometheus\",\"reconcileID\":\"fc8cc145-b97d-412f-81c1-08b73a985ba0\",\"error\":\"invalid chart reference: failed to get chart version for remote reference: no chart name found\"}",
    "detected_severity": "ERROR",
    "signature": "{\"level\":\"error\",\"ts\":\"<TIMESTAMP>\",\"msg\":\"reconciliation stalled\",\"controller\":\"helmchart\",\"controllerGroup\":\"source.toolkit.fluxcd.io\",\"controllerKind\":\"HelmChart\",\"HelmChart\":{\"name\":\"monitoring-prometheus\",\"namespace\":\"flux-system\"},\"namespace\":\"flux-system\",\"name\":\"monitoring-prometheus\",\"reconcileID\":\"<UUID>\",\"error\":\"invalid chart reference: failed to get chart version for remote reference: no chart name found\"}",
    "signature_hash": "dae70660",
    "source": "real",
    "root_cause": "helm_chart_reconciliation_stalled",
    "severity": "error",
    "component": "flux_source_controller",
    "summary": "Flux source controller cannot reconcile HelmChart due to missing chart name",
    "action_needed": "fix_helm_chart_spec"
  },
  {
    "timestamp": 1767037648604.0,
    "timestamp_human": "2025-12-29T13:47:28.604343",
    "namespace": "flux-system",
    "pod": "source-controller-56c7f45479-5c7s2",
    "container": "manager",
    "node": "node-2",
    "log_line": "{\"level\":\"error\",\"ts\":\"2025-12-29T19:47:28.604Z\",\"msg\":\"reconciliation stalled\",\"controller\":\"helmrepository\",\"controllerGroup\":\"source.toolkit.fluxcd.io\",\"controllerKind\":\"HelmRepository\",\"HelmRepository\":{\"name\":\"envoyproxy\",\"namespace\":\"flux-system\"},\"namespace\":\"flux-system\",\"name\":\"envoyproxy\",\"reconcileID\":\"9efc5396-4862-43bb-a4bb-4c509685410f\",\"error\":\"invalid Helm repository URL: 'oci' URL scheme cannot be used with 'default' HelmRepository type\"}",
    "detected_severity": "ERROR",
    "signature": "{\"level\":\"error\",\"ts\":\"<TIMESTAMP>\",\"msg\":\"reconciliation stalled\",\"controller\":\"helmrepository\",\"controllerGroup\":\"source.toolkit.fluxcd.io\",\"controllerKind\":\"HelmRepository\",\"HelmRepository\":{\"name\":\"envoyproxy\",\"namespace\":\"flux-system\"},\"namespace\":\"flux-system\",\"name\":\"envoyproxy\",\"reconcileID\":\"<UUID>\",\"error\":\"invalid Helm repository URL: 'oci' URL scheme cannot be used with 'default' HelmRepository type\"}",
    "signature_hash": "846941ef",
    "source": "real",
    "root_cause": "unknown",
    "severity": "error",
    "component": "flux_system",
    "summary": "Log from flux-system requiring manual review",
    "action_needed": "investigate"
  },
  {
    "timestamp": 1767037011883.0,
    "timestamp_human": "2025-12-29T13:36:51.883034",
    "namespace": "flux-system",
    "pod": "source-controller-56c7f45479-5c7s2",
    "container": "manager",
    "node": "node-2",
    "log_line": "{\"level\":\"error\",\"ts\":\"2025-12-29T19:36:51.882Z\",\"msg\":\"reconciliation stalled\",\"controller\":\"helmrepository\",\"controllerGroup\":\"source.toolkit.fluxcd.io\",\"controllerKind\":\"HelmRepository\",\"HelmRepository\":{\"name\":\"envoyproxy\",\"namespace\":\"flux-system\"},\"namespace\":\"flux-system\",\"name\":\"envoyproxy\",\"reconcileID\":\"b6f8ed1c-1249-4981-aa8b-b8ac10f3ae1a\",\"error\":\"invalid Helm repository URL: 'oci' URL scheme cannot be used with 'default' HelmRepository type\"}",
    "detected_severity": "ERROR",
    "signature": "{\"level\":\"error\",\"ts\":\"<TIMESTAMP>\",\"msg\":\"reconciliation stalled\",\"controller\":\"helmrepository\",\"controllerGroup\":\"source.toolkit.fluxcd.io\",\"controllerKind\":\"HelmRepository\",\"HelmRepository\":{\"name\":\"envoyproxy\",\"namespace\":\"flux-system\"},\"namespace\":\"flux-system\",\"name\":\"envoyproxy\",\"reconcileID\":\"<UUID>\",\"error\":\"invalid Helm repository URL: 'oci' URL scheme cannot be used with 'default' HelmRepository type\"}",
    "signature_hash": "846941ef",
    "source": "real",
    "root_cause": "unknown",
    "severity": "error",
    "component": "flux_system",
    "summary": "Log from flux-system requiring manual review",
    "action_needed": "investigate"
  },
  {
    "timestamp": 1767036880576.0,
    "timestamp_human": "2025-12-29T13:34:40.576716",
    "namespace": "flux-system",
    "pod": "source-controller-56c7f45479-5c7s2",
    "container": "manager",
    "node": "node-2",
    "log_line": "{\"level\":\"error\",\"ts\":\"2025-12-29T19:34:40.576Z\",\"msg\":\"Reconciler error\",\"controller\":\"helmrepository\",\"controllerGroup\":\"source.toolkit.fluxcd.io\",\"controllerKind\":\"HelmRepository\",\"HelmRepository\":{\"name\":\"envoyproxy\",\"namespace\":\"flux-system\"},\"namespace\":\"flux-system\",\"name\":\"envoyproxy\",\"reconcileID\":\"e7e74e97-873b-465b-92d7-6a6f573f359e\",\"error\":\"failed to fetch Helm repository index: failed to cache index to temporary file: failed to fetch https://gateway.envoyproxy.io/index.yaml : 404 Not Found\"}",
    "detected_severity": "ERROR",
    "signature": "{\"level\":\"error\",\"ts\":\"<TIMESTAMP>\",\"msg\":\"Reconciler error\",\"controller\":\"helmrepository\",\"controllerGroup\":\"source.toolkit.fluxcd.io\",\"controllerKind\":\"HelmRepository\",\"HelmRepository\":{\"name\":\"envoyproxy\",\"namespace\":\"flux-system\"},\"namespace\":\"flux-system\",\"name\":\"envoyproxy\",\"reconcileID\":\"<UUID>\",\"error\":\"failed to fetch Helm repository index: failed to cache index to temporary file: failed to fetch https://gateway.envoyproxy.io/index.yaml : 404 Not Found\"}",
    "signature_hash": "eb81f879",
    "source": "real",
    "root_cause": "helm_repo_url_invalid",
    "severity": "error",
    "component": "flux_source_controller",
    "summary": "Helm repository index URL returns 404 (likely wrong URL or moved)",
    "action_needed": "update_helm_repo_url"
  },
  {
    "timestamp": 1767038574895.0,
    "timestamp_human": "2025-12-29T14:02:54.895235",
    "namespace": "flux-system",
    "pod": "helm-controller-74988df57b-jbp6h",
    "container": "manager",
    "node": "node-2",
    "log_line": "{\"level\":\"error\",\"ts\":\"2025-12-29T20:02:54.894Z\",\"msg\":\"Reconciler error\",\"controller\":\"helmrelease\",\"controllerGroup\":\"helm.toolkit.fluxcd.io\",\"controllerKind\":\"HelmRelease\",\"HelmRelease\":{\"name\":\"tempo\",\"namespace\":\"logging\"},\"namespace\":\"logging\",\"name\":\"tempo\",\"reconcileID\":\"d8a9b4fc-b870-444a-8ade-4ee639d130c3\",\"error\":\"terminal error: missing target release for rollback: cannot remediate failed release\"}",
    "detected_severity": "ERROR",
    "signature": "{\"level\":\"error\",\"ts\":\"<TIMESTAMP>\",\"msg\":\"Reconciler error\",\"controller\":\"helmrelease\",\"controllerGroup\":\"helm.toolkit.fluxcd.io\",\"controllerKind\":\"HelmRelease\",\"HelmRelease\":{\"name\":\"tempo\",\"namespace\":\"logging\"},\"namespace\":\"logging\",\"name\":\"tempo\",\"reconcileID\":\"<UUID>\",\"error\":\"terminal error: missing target release for rollback: cannot remediate failed release\"}",
    "signature_hash": "2f516100",
    "source": "real",
    "root_cause": "unknown",
    "severity": "error",
    "component": "flux_system",
    "summary": "Log from flux-system requiring manual review",
    "action_needed": "investigate"
  },
  {
    "timestamp": 1767038406599.0,
    "timestamp_human": "2025-12-29T14:00:06.599760",
    "namespace": "flux-system",
    "pod": "helm-controller-74988df57b-jbp6h",
    "container": "manager",
    "node": "node-2",
    "log_line": "{\"level\":\"error\",\"ts\":\"2025-12-29T20:00:06.599Z\",\"msg\":\"Reconciler error\",\"controller\":\"helmrelease\",\"controllerGroup\":\"helm.toolkit.fluxcd.io\",\"controllerKind\":\"HelmRelease\",\"HelmRelease\":{\"name\":\"tempo\",\"namespace\":\"logging\"},\"namespace\":\"logging\",\"name\":\"tempo\",\"reconcileID\":\"28949acd-3843-47d8-a04e-4334afe61a7b\",\"error\":\"terminal error: missing target release for rollback: cannot remediate failed release\"}",
    "detected_severity": "ERROR",
    "signature": "{\"level\":\"error\",\"ts\":\"<TIMESTAMP>\",\"msg\":\"Reconciler error\",\"controller\":\"helmrelease\",\"controllerGroup\":\"helm.toolkit.fluxcd.io\",\"controllerKind\":\"HelmRelease\",\"HelmRelease\":{\"name\":\"tempo\",\"namespace\":\"logging\"},\"namespace\":\"logging\",\"name\":\"tempo\",\"reconcileID\":\"<UUID>\",\"error\":\"terminal error: missing target release for rollback: cannot remediate failed release\"}",
    "signature_hash": "2f516100",
    "source": "real",
    "root_cause": "unknown",
    "severity": "error",
    "component": "flux_system",
    "summary": "Log from flux-system requiring manual review",
    "action_needed": "investigate"
  },
  {
    "timestamp": 1767037346801.0,
    "timestamp_human": "2025-12-29T13:42:26.801024",
    "namespace": "flux-system",
    "pod": "helm-controller-74988df57b-jbp6h",
    "container": "manager",
    "node": "node-2",
    "log_line": "{\"level\":\"error\",\"ts\":\"2025-12-29T19:42:26.800Z\",\"msg\":\"Reconciler error\",\"controller\":\"helmrelease\",\"controllerGroup\":\"helm.toolkit.fluxcd.io\",\"controllerKind\":\"HelmRelease\",\"HelmRelease\":{\"name\":\"grafana\",\"namespace\":\"logging\"},\"namespace\":\"logging\",\"name\":\"grafana\",\"reconcileID\":\"e79228e1-bd08-48eb-9019-7b7d00b09697\",\"error\":\"terminal error: exceeded maximum retries: cannot remediate failed release\"}",
    "detected_severity": "ERROR",
    "signature": "{\"level\":\"error\",\"ts\":\"<TIMESTAMP>\",\"msg\":\"Reconciler error\",\"controller\":\"helmrelease\",\"controllerGroup\":\"helm.toolkit.fluxcd.io\",\"controllerKind\":\"HelmRelease\",\"HelmRelease\":{\"name\":\"grafana\",\"namespace\":\"logging\"},\"namespace\":\"logging\",\"name\":\"grafana\",\"reconcileID\":\"<UUID>\",\"error\":\"terminal error: exceeded maximum retries: cannot remediate failed release\"}",
    "signature_hash": "5ea92b55",
    "source": "real",
    "root_cause": "helm_release_max_retries",
    "severity": "critical",
    "component": "flux_helm_controller",
    "summary": "Flux exhausted retry attempts and cannot remediate failed Grafana release",
    "action_needed": "manual_helm_intervention"
  },
  {
    "timestamp": 1767037345555.0,
    "timestamp_human": "2025-12-29T13:42:25.555123",
    "namespace": "flux-system",
    "pod": "helm-controller-74988df57b-jbp6h",
    "container": "manager",
    "node": "node-2",
    "log_line": "{\"level\":\"error\",\"ts\":\"2025-12-29T19:42:25.554Z\",\"msg\":\"Reconciler error\",\"controller\":\"helmrelease\",\"controllerGroup\":\"helm.toolkit.fluxcd.io\",\"controllerKind\":\"HelmRelease\",\"HelmRelease\":{\"name\":\"tempo\",\"namespace\":\"logging\"},\"namespace\":\"logging\",\"name\":\"tempo\",\"reconcileID\":\"2a906713-7598-4fa9-9b20-a0a1bbc30b22\",\"error\":\"terminal error: exceeded maximum retries: cannot remediate failed release\"}",
    "detected_severity": "ERROR",
    "signature": "{\"level\":\"error\",\"ts\":\"<TIMESTAMP>\",\"msg\":\"Reconciler error\",\"controller\":\"helmrelease\",\"controllerGroup\":\"helm.toolkit.fluxcd.io\",\"controllerKind\":\"HelmRelease\",\"HelmRelease\":{\"name\":\"tempo\",\"namespace\":\"logging\"},\"namespace\":\"logging\",\"name\":\"tempo\",\"reconcileID\":\"<UUID>\",\"error\":\"terminal error: exceeded maximum retries: cannot remediate failed release\"}",
    "signature_hash": "54bc41dc",
    "source": "real",
    "root_cause": "helm_release_max_retries",
    "severity": "critical",
    "component": "flux_helm_controller",
    "summary": "Flux exhausted retry attempts and cannot remediate failed release",
    "action_needed": "manual_helm_intervention"
  },
  {
    "timestamp": 1767037345430.0,
    "timestamp_human": "2025-12-29T13:42:25.430166",
    "namespace": "flux-system",
    "pod": "helm-controller-74988df57b-jbp6h",
    "container": "manager",
    "node": "node-2",
    "log_line": "{\"level\":\"error\",\"ts\":\"2025-12-29T19:42:25.429Z\",\"msg\":\"Reconciler error\",\"controller\":\"helmrelease\",\"controllerGroup\":\"helm.toolkit.fluxcd.io\",\"controllerKind\":\"HelmRelease\",\"HelmRelease\":{\"name\":\"tempo\",\"namespace\":\"logging\"},\"namespace\":\"logging\",\"name\":\"tempo\",\"reconcileID\":\"bf7aa74a-1041-4b49-9193-e1ffcba5aef7\",\"error\":\"terminal error: exceeded maximum retries: cannot remediate failed release\"}",
    "detected_severity": "ERROR",
    "signature": "{\"level\":\"error\",\"ts\":\"<TIMESTAMP>\",\"msg\":\"Reconciler error\",\"controller\":\"helmrelease\",\"controllerGroup\":\"helm.toolkit.fluxcd.io\",\"controllerKind\":\"HelmRelease\",\"HelmRelease\":{\"name\":\"tempo\",\"namespace\":\"logging\"},\"namespace\":\"logging\",\"name\":\"tempo\",\"reconcileID\":\"<UUID>\",\"error\":\"terminal error: exceeded maximum retries: cannot remediate failed release\"}",
    "signature_hash": "54bc41dc",
    "source": "real",
    "root_cause": "helm_release_max_retries",
    "severity": "critical",
    "component": "flux_helm_controller",
    "summary": "Flux exhausted retry attempts and cannot remediate failed release",
    "action_needed": "manual_helm_intervention"
  },
  {
    "timestamp": 1767037046166.0,
    "timestamp_human": "2025-12-29T13:37:26.166958",
    "namespace": "flux-system",
    "pod": "helm-controller-74988df57b-jbp6h",
    "container": "manager",
    "node": "node-2",
    "log_line": "{\"level\":\"error\",\"ts\":\"2025-12-29T19:37:26.166Z\",\"msg\":\"failed to wait for object to sync in-cache after patching\",\"controller\":\"helmrelease\",\"controllerGroup\":\"helm.toolkit.fluxcd.io\",\"controllerKind\":\"HelmRelease\",\"HelmRelease\":{\"name\":\"grafana\",\"namespace\":\"logging\"},\"namespace\":\"logging\",\"name\":\"grafana\",\"reconcileID\":\"d9517e4b-42bf-4d48-b90c-3cd32191ca3f\",\"error\":\"context deadline exceeded\"}",
    "detected_severity": "ERROR",
    "signature": "{\"level\":\"error\",\"ts\":\"<TIMESTAMP>\",\"msg\":\"failed to wait for object to sync in-cache after patching\",\"controller\":\"helmrelease\",\"controllerGroup\":\"helm.toolkit.fluxcd.io\",\"controllerKind\":\"HelmRelease\",\"HelmRelease\":{\"name\":\"grafana\",\"namespace\":\"logging\"},\"namespace\":\"logging\",\"name\":\"grafana\",\"reconcileID\":\"<UUID>\",\"error\":\"context deadline exceeded\"}",
    "signature_hash": "884d8655",
    "source": "real",
    "root_cause": "unknown",
    "severity": "error",
    "component": "flux_system",
    "summary": "Log from flux-system requiring manual review",
    "action_needed": "investigate"
  },
  {
    "timestamp": 1767036735215.0,
    "timestamp_human": "2025-12-29T13:32:15.215976",
    "namespace": "flux-system",
    "pod": "helm-controller-74988df57b-jbp6h",
    "container": "manager",
    "node": "node-2",
    "log_line": "{\"level\":\"error\",\"ts\":\"2025-12-29T19:32:15.215Z\",\"msg\":\"failed to wait for object to sync in-cache after patching\",\"controller\":\"helmrelease\",\"controllerGroup\":\"helm.toolkit.fluxcd.io\",\"controllerKind\":\"HelmRelease\",\"HelmRelease\":{\"name\":\"grafana\",\"namespace\":\"logging\"},\"namespace\":\"logging\",\"name\":\"grafana\",\"reconcileID\":\"1bfdd332-f5de-4391-ac21-ba915c33953f\",\"error\":\"context deadline exceeded\"}",
    "detected_severity": "ERROR",
    "signature": "{\"level\":\"error\",\"ts\":\"<TIMESTAMP>\",\"msg\":\"failed to wait for object to sync in-cache after patching\",\"controller\":\"helmrelease\",\"controllerGroup\":\"helm.toolkit.fluxcd.io\",\"controllerKind\":\"HelmRelease\",\"HelmRelease\":{\"name\":\"grafana\",\"namespace\":\"logging\"},\"namespace\":\"logging\",\"name\":\"grafana\",\"reconcileID\":\"<UUID>\",\"error\":\"context deadline exceeded\"}",
    "signature_hash": "884d8655",
    "source": "real",
    "root_cause": "unknown",
    "severity": "error",
    "component": "flux_system",
    "summary": "Log from flux-system requiring manual review",
    "action_needed": "investigate"
  },
  {
    "timestamp": 1767037044955.0,
    "timestamp_human": "2025-12-29T13:37:24.955998",
    "namespace": "flux-system",
    "pod": "helm-controller-74988df57b-jbp6h",
    "container": "manager",
    "node": "node-2",
    "log_line": "{\"level\":\"error\",\"ts\":\"2025-12-29T19:37:24.955Z\",\"msg\":\"failed to wait for object to sync in-cache after patching\",\"controller\":\"helmrelease\",\"controllerGroup\":\"helm.toolkit.fluxcd.io\",\"controllerKind\":\"HelmRelease\",\"HelmRelease\":{\"name\":\"tempo\",\"namespace\":\"logging\"},\"namespace\":\"logging\",\"name\":\"tempo\",\"reconcileID\":\"adc9eb6b-f15b-4d26-a237-7ac465144364\",\"error\":\"context deadline exceeded\"}",
    "detected_severity": "ERROR",
    "signature": "{\"level\":\"error\",\"ts\":\"<TIMESTAMP>\",\"msg\":\"failed to wait for object to sync in-cache after patching\",\"controller\":\"helmrelease\",\"controllerGroup\":\"helm.toolkit.fluxcd.io\",\"controllerKind\":\"HelmRelease\",\"HelmRelease\":{\"name\":\"tempo\",\"namespace\":\"logging\"},\"namespace\":\"logging\",\"name\":\"tempo\",\"reconcileID\":\"<UUID>\",\"error\":\"context deadline exceeded\"}",
    "signature_hash": "7d6690cf",
    "source": "real",
    "root_cause": "unknown",
    "severity": "error",
    "component": "flux_system",
    "summary": "Log from flux-system requiring manual review",
    "action_needed": "investigate"
  },
  {
    "timestamp": 1767036734302.0,
    "timestamp_human": "2025-12-29T13:32:14.302522",
    "namespace": "flux-system",
    "pod": "helm-controller-74988df57b-jbp6h",
    "container": "manager",
    "node": "node-2",
    "log_line": "{\"level\":\"error\",\"ts\":\"2025-12-29T19:32:14.302Z\",\"msg\":\"failed to wait for object to sync in-cache after patching\",\"controller\":\"helmrelease\",\"controllerGroup\":\"helm.toolkit.fluxcd.io\",\"controllerKind\":\"HelmRelease\",\"HelmRelease\":{\"name\":\"tempo\",\"namespace\":\"logging\"},\"namespace\":\"logging\",\"name\":\"tempo\",\"reconcileID\":\"3900dcc0-53f5-4ad7-8483-076b6814e86a\",\"error\":\"context deadline exceeded\"}",
    "detected_severity": "ERROR",
    "signature": "{\"level\":\"error\",\"ts\":\"<TIMESTAMP>\",\"msg\":\"failed to wait for object to sync in-cache after patching\",\"controller\":\"helmrelease\",\"controllerGroup\":\"helm.toolkit.fluxcd.io\",\"controllerKind\":\"HelmRelease\",\"HelmRelease\":{\"name\":\"tempo\",\"namespace\":\"logging\"},\"namespace\":\"logging\",\"name\":\"tempo\",\"reconcileID\":\"<UUID>\",\"error\":\"context deadline exceeded\"}",
    "signature_hash": "7d6690cf",
    "source": "real",
    "root_cause": "unknown",
    "severity": "error",
    "component": "flux_system",
    "summary": "Log from flux-system requiring manual review",
    "action_needed": "investigate"
  },
  {
    "timestamp": 1767054957303.0,
    "timestamp_human": "2025-12-29T18:35:57.303580",
    "namespace": "envoy-gateway-system",
    "pod": "envoy-gateway-c9dd54486-csq78",
    "container": "envoy-gateway",
    "node": "node-2",
    "log_line": "2025-12-30T00:35:57.303Z\tINFO\tprovider.KubeAPIWarningLogger\tlog/warning_handler.go:65\tmetadata.finalizers: \"gateway-exists-finalizer.gateway.networking.k8s.io\": prefer a domain-qualified finalizer name including a path (/) to avoid accidental conflicts with other finalizer writers\t{\"runner\": \"provider\"}",
    "detected_severity": "WARN",
    "signature": "<TIMESTAMP>\tINFO\tprovider.KubeAPIWarningLogger\tlog/warning_handler.go:<PORT>\tmetadata.finalizers: \"gateway-<POD>izer.gateway.networking.k8s.io\": prefer a domain-qualified finalizer name including a path (/) to avoid accidental conflicts with other finalizer writers\t{\"runner\": \"provider\"}",
    "signature_hash": "1bef9e42",
    "source": "real",
    "root_cause": "k8s_api_deprecation_warning",
    "severity": "info",
    "component": "envoy_gateway",
    "summary": "Kubernetes API warning about finalizer naming convention (non-critical)",
    "action_needed": "none"
  },
  {
    "timestamp": 1766799145577.0,
    "timestamp_human": "2025-12-26T19:32:25.577984",
    "namespace": "envoy-gateway-system",
    "pod": "envoy-gateway-775d8bf958-ldd5t",
    "container": "envoy-gateway",
    "node": "node-1",
    "log_line": "2025-12-27T01:32:25.577Z\tERROR\tprovider\tcache/reflector.go:200\tFailed to watch\t{\"runner\": \"provider\", \"logger\": \"UnhandledError\", \"reflector\": \"pkg/mod/k8s.io/client-go@v0.33.0/tools/cache/reflector.go:285\", \"type\": \"*v1alpha1.SecurityPolicy\", \"error\": \"securitypolicies.gateway.envoyproxy.io is forbidden: User \\\"system:serviceaccount:envoy-gateway-system:envoy-gateway\\\" cannot watch resource \\\"securitypolicies\\\" in API group \\\"gateway.envoyproxy.io\\\" at the cluster scope: RBAC: [clusterrole.rbac.authorization.k8s.io \\\"system:service-account-issuer-discovery\\\" not found, clusterrole.rbac.authorization.k8s.io \\\"eg-gateway-helm-envoy-gateway-role\\\" not found, clusterrole.rbac.authorization.k8s.io \\\"system:basic-user\\\" not found, clusterrole.rbac.authorization.k8s.io \\\"system:public-info-viewer\\\" not found, clusterrole.rbac.authorization.k8s.io \\\"system:discovery\\\" not found]\"}",
    "detected_severity": "ERROR",
    "signature": "<TIMESTAMP>\tERROR\tprovider\tcache/reflector.go:<PORT>\tFailed to watch\t{\"runner\": \"provider\", \"logger\": \"UnhandledError\", \"reflector\": \"pkg/mod/k8s.io/client-go@v0.33.0/tools/cache/reflector.go:<PORT>\", \"type\": \"*v1alpha1.SecurityPolicy\", \"error\": \"securitypolicies.gateway.envoyproxy.io is forbidden: User \\\"system:serviceaccount:envoy-<POD>m:envoy-gateway\\\" cannot watch resource \\\"securitypolicies\\\" in API group \\\"gateway.envoyproxy.io\\\" at the cluster scope: RBAC: [clusterrole.rbac.authorization.k8s.io \\\"system:service-<POD>r-discovery\\\" not found, clusterrole.rbac.authorization.k8s.io \\\"eg-gateway-helm-<POD>ay-role\\\" not found, clusterrole.rbac.authorization.k8s.io \\\"system:basic-user\\\" not found, clusterrole.rbac.authorization.k8s.io \\\"system:public-info-viewer\\\" not found, clusterrole.rbac.authorization.k8s.io \\\"system:discovery\\\" not found]\"}",
    "signature_hash": "9a2198c4",
    "source": "real",
    "root_cause": "unknown",
    "severity": "error",
    "component": "envoy_gateway_system",
    "summary": "Log from envoy-gateway-system requiring manual review",
    "action_needed": "investigate"
  },
  {
    "timestamp": 1766970705892.0,
    "timestamp_human": "2025-12-28T19:11:45.892111",
    "namespace": "envoy-gateway-system",
    "pod": "envoy-gateway-775d8bf958-ldd5t",
    "container": "envoy-gateway",
    "node": "node-1",
    "log_line": "2025-12-29T01:11:45.891Z\tERROR\tprovider\tleaderelection/leaderelection.go:436\terror retrieving resource lock envoy-gateway-system/5b9825d2.gateway.envoyproxy.io: Get \"https://10.43.0.1:443/apis/coordination.k8s.io/v1/namespaces/envoy-gateway-system/leases/5b9825d2.gateway.envoyproxy.io?timeout=5s\": dial tcp 10.43.0.1:443: connect: connection refused\t{\"runner\": \"provider\"}",
    "detected_severity": "ERROR",
    "signature": "<TIMESTAMP>\tERROR\tprovider\tleaderelection/leaderelection.go:<PORT>\terror retrieving resource lock envoy-<POD>m/5b9825d2.gateway.envoyproxy.io: Get \"https://<IP>:<PORT>/apis/coordination.k8s.io/v1/namespaces/envoy-<POD>m/leases/5b9825d2.gateway.envoyproxy.io?timeout=5s\": dial tcp <IP>:<PORT>: connect: connection refused\t{\"runner\": \"provider\"}",
    "signature_hash": "7048c42e",
    "source": "real",
    "root_cause": "unknown",
    "severity": "error",
    "component": "envoy_gateway_system",
    "summary": "Log from envoy-gateway-system requiring manual review",
    "action_needed": "investigate"
  },
  {
    "timestamp": 1766959264900.0,
    "timestamp_human": "2025-12-28T16:01:04.900725",
    "namespace": "envoy-gateway-system",
    "pod": "envoy-gateway-775d8bf958-ldd5t",
    "container": "envoy-gateway",
    "node": "node-1",
    "log_line": "2025-12-28T22:01:04.900Z\tERROR\tprovider\tleaderelection/leaderelection.go:436\terror retrieving resource lock envoy-gateway-system/5b9825d2.gateway.envoyproxy.io: Get \"https://10.43.0.1:443/apis/coordination.k8s.io/v1/namespaces/envoy-gateway-system/leases/5b9825d2.gateway.envoyproxy.io?timeout=5s\": dial tcp 10.43.0.1:443: connect: connection refused\t{\"runner\": \"provider\"}",
    "detected_severity": "ERROR",
    "signature": "<TIMESTAMP>\tERROR\tprovider\tleaderelection/leaderelection.go:<PORT>\terror retrieving resource lock envoy-<POD>m/5b9825d2.gateway.envoyproxy.io: Get \"https://<IP>:<PORT>/apis/coordination.k8s.io/v1/namespaces/envoy-<POD>m/leases/5b9825d2.gateway.envoyproxy.io?timeout=5s\": dial tcp <IP>:<PORT>: connect: connection refused\t{\"runner\": \"provider\"}",
    "signature_hash": "7048c42e",
    "source": "real",
    "root_cause": "unknown",
    "severity": "error",
    "component": "envoy_gateway_system",
    "summary": "Log from envoy-gateway-system requiring manual review",
    "action_needed": "investigate"
  },
  {
    "timestamp": 1766970705891.0,
    "timestamp_human": "2025-12-28T19:11:45.891271",
    "namespace": "envoy-gateway-system",
    "pod": "envoy-gateway-775d8bf958-ldd5t",
    "container": "envoy-gateway",
    "node": "node-1",
    "log_line": "2025-12-29T01:11:45.890Z\tERROR\tprovider\tleaderelection/leaderelection.go:429\tFailed to update lock optimistically: Put \"https://10.43.0.1:443/apis/coordination.k8s.io/v1/namespaces/envoy-gateway-system/leases/5b9825d2.gateway.envoyproxy.io?timeout=5s\": dial tcp 10.43.0.1:443: connect: connection refused, falling back to slow path\t{\"runner\": \"provider\"}",
    "detected_severity": "ERROR",
    "signature": "<TIMESTAMP>\tERROR\tprovider\tleaderelection/leaderelection.go:<PORT>\tFailed to update lock optimistically: Put \"https://<IP>:<PORT>/apis/coordination.k8s.io/v1/namespaces/envoy-<POD>m/leases/5b9825d2.gateway.envoyproxy.io?timeout=5s\": dial tcp <IP>:<PORT>: connect: connection refused, falling back to slow path\t{\"runner\": \"provider\"}",
    "signature_hash": "0e3bf612",
    "source": "real",
    "root_cause": "leader_election_apiserver_unavailable",
    "severity": "error",
    "component": "envoy_gateway",
    "summary": "Envoy Gateway cannot reach API server for leader election, using fallback",
    "action_needed": "check_apiserver_connectivity"
  },
  {
    "timestamp": 1766959264899.0,
    "timestamp_human": "2025-12-28T16:01:04.899848",
    "namespace": "envoy-gateway-system",
    "pod": "envoy-gateway-775d8bf958-ldd5t",
    "container": "envoy-gateway",
    "node": "node-1",
    "log_line": "2025-12-28T22:01:04.899Z\tERROR\tprovider\tleaderelection/leaderelection.go:429\tFailed to update lock optimistically: Put \"https://10.43.0.1:443/apis/coordination.k8s.io/v1/namespaces/envoy-gateway-system/leases/5b9825d2.gateway.envoyproxy.io?timeout=5s\": dial tcp 10.43.0.1:443: connect: connection refused, falling back to slow path\t{\"runner\": \"provider\"}",
    "detected_severity": "ERROR",
    "signature": "<TIMESTAMP>\tERROR\tprovider\tleaderelection/leaderelection.go:<PORT>\tFailed to update lock optimistically: Put \"https://<IP>:<PORT>/apis/coordination.k8s.io/v1/namespaces/envoy-<POD>m/leases/5b9825d2.gateway.envoyproxy.io?timeout=5s\": dial tcp <IP>:<PORT>: connect: connection refused, falling back to slow path\t{\"runner\": \"provider\"}",
    "signature_hash": "0e3bf612",
    "source": "real",
    "root_cause": "leader_election_apiserver_unavailable",
    "severity": "error",
    "component": "envoy_gateway",
    "summary": "Envoy Gateway cannot reach API server for leader election, using fallback",
    "action_needed": "check_apiserver_connectivity"
  },
  {
    "timestamp": 1766958940716.0,
    "timestamp_human": "2025-12-28T15:55:40.716508",
    "namespace": "envoy-gateway-system",
    "pod": "envoy-gateway-775d8bf958-ldd5t",
    "container": "envoy-gateway",
    "node": "node-1",
    "log_line": "2025-12-28T21:55:40.484Z\tERROR\tprovider\tcache/reflector.go:200\tFailed to watch\t{\"runner\": \"provider\", \"logger\": \"UnhandledError\", \"reflector\": \"pkg/mod/k8s.io/client-go@v0.33.0/tools/cache/reflector.go:285\", \"type\": \"*v1alpha1.EnvoyPatchPolicy\", \"error\": \"apiserver not ready\"}",
    "detected_severity": "ERROR",
    "signature": "<TIMESTAMP>\tERROR\tprovider\tcache/reflector.go:<PORT>\tFailed to watch\t{\"runner\": \"provider\", \"logger\": \"UnhandledError\", \"reflector\": \"pkg/mod/k8s.io/client-go@v0.33.0/tools/cache/reflector.go:<PORT>\", \"type\": \"*v1alpha1.EnvoyPatchPolicy\", \"error\": \"apiserver not ready\"}",
    "signature_hash": "b42e7b55",
    "source": "real",
    "root_cause": "apiserver_not_ready",
    "severity": "error",
    "component": "envoy_gateway",
    "summary": "Envoy Gateway cannot watch resources because API server is not ready",
    "action_needed": "wait_for_apiserver"
  },
  {
    "timestamp": 1766958940716.0,
    "timestamp_human": "2025-12-28T15:55:40.716506",
    "namespace": "envoy-gateway-system",
    "pod": "envoy-gateway-775d8bf958-ldd5t",
    "container": "envoy-gateway",
    "node": "node-1",
    "log_line": "2025-12-28T21:55:40.377Z\tERROR\tprovider\tcache/reflector.go:200\tFailed to watch\t{\"runner\": \"provider\", \"logger\": \"UnhandledError\", \"reflector\": \"pkg/mod/k8s.io/client-go@v0.33.0/tools/cache/reflector.go:285\", \"type\": \"*v1alpha1.EnvoyProxy\", \"error\": \"apiserver not ready\"}",
    "detected_severity": "ERROR",
    "signature": "<TIMESTAMP>\tERROR\tprovider\tcache/reflector.go:<PORT>\tFailed to watch\t{\"runner\": \"provider\", \"logger\": \"UnhandledError\", \"reflector\": \"pkg/mod/k8s.io/client-go@v0.33.0/tools/cache/reflector.go:<PORT>\", \"type\": \"*v1alpha1.EnvoyProxy\", \"error\": \"apiserver not ready\"}",
    "signature_hash": "2bc4d9f4",
    "source": "real",
    "root_cause": "apiserver_not_ready",
    "severity": "error",
    "component": "envoy_gateway",
    "summary": "Envoy Gateway cannot watch resources because API server is not ready",
    "action_needed": "wait_for_apiserver"
  },
  {
    "timestamp": 1766958940716.0,
    "timestamp_human": "2025-12-28T15:55:40.716501",
    "namespace": "envoy-gateway-system",
    "pod": "envoy-gateway-775d8bf958-ldd5t",
    "container": "envoy-gateway",
    "node": "node-1",
    "log_line": "2025-12-28T21:55:40.373Z\tERROR\tprovider\tcache/reflector.go:200\tFailed to watch\t{\"runner\": \"provider\", \"logger\": \"UnhandledError\", \"reflector\": \"pkg/mod/k8s.io/client-go@v0.33.0/tools/cache/reflector.go:285\", \"type\": \"*v1.Deployment\", \"error\": \"apiserver not ready\"}",
    "detected_severity": "ERROR",
    "signature": "<TIMESTAMP>\tERROR\tprovider\tcache/reflector.go:<PORT>\tFailed to watch\t{\"runner\": \"provider\", \"logger\": \"UnhandledError\", \"reflector\": \"pkg/mod/k8s.io/client-go@v0.33.0/tools/cache/reflector.go:<PORT>\", \"type\": \"*v1.Deployment\", \"error\": \"apiserver not ready\"}",
    "signature_hash": "a3ff94e2",
    "source": "real",
    "root_cause": "apiserver_not_ready",
    "severity": "error",
    "component": "envoy_gateway",
    "summary": "Envoy Gateway cannot watch Deployments because API server is not ready",
    "action_needed": "wait_for_apiserver"
  },
  {
    "timestamp": 1766958940716.0,
    "timestamp_human": "2025-12-28T15:55:40.716496",
    "namespace": "envoy-gateway-system",
    "pod": "envoy-gateway-775d8bf958-ldd5t",
    "container": "envoy-gateway",
    "node": "node-1",
    "log_line": "2025-12-28T21:55:40.351Z\tERROR\tprovider\tcache/reflector.go:200\tFailed to watch\t{\"runner\": \"provider\", \"logger\": \"UnhandledError\", \"reflector\": \"pkg/mod/k8s.io/client-go@v0.33.0/tools/cache/reflector.go:285\", \"type\": \"*v1alpha1.EnvoyExtensionPolicy\", \"error\": \"apiserver not ready\"}",
    "detected_severity": "ERROR",
    "signature": "<TIMESTAMP>\tERROR\tprovider\tcache/reflector.go:<PORT>\tFailed to watch\t{\"runner\": \"provider\", \"logger\": \"UnhandledError\", \"reflector\": \"pkg/mod/k8s.io/client-go@v0.33.0/tools/cache/reflector.go:<PORT>\", \"type\": \"*v1alpha1.EnvoyExtensionPolicy\", \"error\": \"apiserver not ready\"}",
    "signature_hash": "690bfcea",
    "source": "real",
    "root_cause": "apiserver_not_ready",
    "severity": "error",
    "component": "envoy_gateway",
    "summary": "Envoy Gateway cannot watch resources because API server is not ready",
    "action_needed": "wait_for_apiserver"
  },
  {
    "timestamp": 1766958940716.0,
    "timestamp_human": "2025-12-28T15:55:40.716494",
    "namespace": "envoy-gateway-system",
    "pod": "envoy-gateway-775d8bf958-ldd5t",
    "container": "envoy-gateway",
    "node": "node-1",
    "log_line": "2025-12-28T21:55:40.324Z\tERROR\tprovider\tcache/reflector.go:200\tFailed to watch\t{\"runner\": \"provider\", \"logger\": \"UnhandledError\", \"reflector\": \"pkg/mod/k8s.io/client-go@v0.33.0/tools/cache/reflector.go:285\", \"type\": \"*v1.EndpointSlice\", \"error\": \"apiserver not ready\"}",
    "detected_severity": "ERROR",
    "signature": "<TIMESTAMP>\tERROR\tprovider\tcache/reflector.go:<PORT>\tFailed to watch\t{\"runner\": \"provider\", \"logger\": \"UnhandledError\", \"reflector\": \"pkg/mod/k8s.io/client-go@v0.33.0/tools/cache/reflector.go:<PORT>\", \"type\": \"*v1.EndpointSlice\", \"error\": \"apiserver not ready\"}",
    "signature_hash": "60713dac",
    "source": "real",
    "root_cause": "apiserver_not_ready",
    "severity": "error",
    "component": "envoy_gateway",
    "summary": "Envoy Gateway cannot watch resources because API server is not ready",
    "action_needed": "wait_for_apiserver"
  },
  {
    "timestamp": 1766958940716.0,
    "timestamp_human": "2025-12-28T15:55:40.716492",
    "namespace": "envoy-gateway-system",
    "pod": "envoy-gateway-775d8bf958-ldd5t",
    "container": "envoy-gateway",
    "node": "node-1",
    "log_line": "2025-12-28T21:55:40.321Z\tERROR\tprovider\tcache/reflector.go:200\tFailed to watch\t{\"runner\": \"provider\", \"logger\": \"UnhandledError\", \"reflector\": \"pkg/mod/k8s.io/client-go@v0.33.0/tools/cache/reflector.go:285\", \"type\": \"*v1.ConfigMap\", \"error\": \"apiserver not ready\"}",
    "detected_severity": "ERROR",
    "signature": "<TIMESTAMP>\tERROR\tprovider\tcache/reflector.go:<PORT>\tFailed to watch\t{\"runner\": \"provider\", \"logger\": \"UnhandledError\", \"reflector\": \"pkg/mod/k8s.io/client-go@v0.33.0/tools/cache/reflector.go:<PORT>\", \"type\": \"*v1.ConfigMap\", \"error\": \"apiserver not ready\"}",
    "signature_hash": "12a0e57e",
    "source": "real",
    "root_cause": "apiserver_not_ready",
    "severity": "error",
    "component": "envoy_gateway",
    "summary": "Envoy Gateway cannot watch resources because API server is not ready",
    "action_needed": "wait_for_apiserver"
  },
  {
    "timestamp": 1766958940716.0,
    "timestamp_human": "2025-12-28T15:55:40.716490",
    "namespace": "envoy-gateway-system",
    "pod": "envoy-gateway-775d8bf958-ldd5t",
    "container": "envoy-gateway",
    "node": "node-1",
    "log_line": "2025-12-28T21:55:40.307Z\tERROR\tprovider\tcache/reflector.go:200\tFailed to watch\t{\"runner\": \"provider\", \"logger\": \"UnhandledError\", \"reflector\": \"pkg/mod/k8s.io/client-go@v0.33.0/tools/cache/reflector.go:285\", \"type\": \"*v1alpha2.TCPRoute\", \"error\": \"apiserver not ready\"}",
    "detected_severity": "ERROR",
    "signature": "<TIMESTAMP>\tERROR\tprovider\tcache/reflector.go:<PORT>\tFailed to watch\t{\"runner\": \"provider\", \"logger\": \"UnhandledError\", \"reflector\": \"pkg/mod/k8s.io/client-go@v0.33.0/tools/cache/reflector.go:<PORT>\", \"type\": \"*v1alpha2.TCPRoute\", \"error\": \"apiserver not ready\"}",
    "signature_hash": "4ecdbd71",
    "source": "real",
    "root_cause": "apiserver_not_ready",
    "severity": "error",
    "component": "envoy_gateway",
    "summary": "Envoy Gateway cannot watch TCPRoutes because API server is not ready",
    "action_needed": "wait_for_apiserver"
  },
  {
    "timestamp": 1766958940716.0,
    "timestamp_human": "2025-12-28T15:55:40.716488",
    "namespace": "envoy-gateway-system",
    "pod": "envoy-gateway-775d8bf958-ldd5t",
    "container": "envoy-gateway",
    "node": "node-1",
    "log_line": "2025-12-28T21:55:40.300Z\tERROR\tprovider\tcache/reflector.go:200\tFailed to watch\t{\"runner\": \"provider\", \"logger\": \"UnhandledError\", \"reflector\": \"pkg/mod/k8s.io/client-go@v0.33.0/tools/cache/reflector.go:285\", \"type\": \"*v1.Namespace\", \"error\": \"apiserver not ready\"}",
    "detected_severity": "ERROR",
    "signature": "<TIMESTAMP>\tERROR\tprovider\tcache/reflector.go:<PORT>\tFailed to watch\t{\"runner\": \"provider\", \"logger\": \"UnhandledError\", \"reflector\": \"pkg/mod/k8s.io/client-go@v0.33.0/tools/cache/reflector.go:<PORT>\", \"type\": \"*v1.Namespace\", \"error\": \"apiserver not ready\"}",
    "signature_hash": "13e1c7d0",
    "source": "real",
    "root_cause": "apiserver_not_ready",
    "severity": "error",
    "component": "envoy_gateway",
    "summary": "Envoy Gateway cannot watch resources because API server is not ready",
    "action_needed": "wait_for_apiserver"
  },
  {
    "timestamp": 1766958940716.0,
    "timestamp_human": "2025-12-28T15:55:40.716486",
    "namespace": "envoy-gateway-system",
    "pod": "envoy-gateway-775d8bf958-ldd5t",
    "container": "envoy-gateway",
    "node": "node-1",
    "log_line": "2025-12-28T21:55:40.295Z\tERROR\tprovider\tcache/reflector.go:200\tFailed to watch\t{\"runner\": \"provider\", \"logger\": \"UnhandledError\", \"reflector\": \"pkg/mod/k8s.io/client-go@v0.33.0/tools/cache/reflector.go:285\", \"type\": \"*v1.Node\", \"error\": \"apiserver not ready\"}",
    "detected_severity": "ERROR",
    "signature": "<TIMESTAMP>\tERROR\tprovider\tcache/reflector.go:<PORT>\tFailed to watch\t{\"runner\": \"provider\", \"logger\": \"UnhandledError\", \"reflector\": \"pkg/mod/k8s.io/client-go@v0.33.0/tools/cache/reflector.go:<PORT>\", \"type\": \"*v1.Node\", \"error\": \"apiserver not ready\"}",
    "signature_hash": "0a28130c",
    "source": "real",
    "root_cause": "apiserver_not_ready",
    "severity": "error",
    "component": "envoy_gateway",
    "summary": "Envoy Gateway cannot watch resources because API server is not ready",
    "action_needed": "wait_for_apiserver"
  },
  {
    "timestamp": 1766958940716.0,
    "timestamp_human": "2025-12-28T15:55:40.716484",
    "namespace": "envoy-gateway-system",
    "pod": "envoy-gateway-775d8bf958-ldd5t",
    "container": "envoy-gateway",
    "node": "node-1",
    "log_line": "2025-12-28T21:55:40.289Z\tERROR\tprovider\tcache/reflector.go:200\tFailed to watch\t{\"runner\": \"provider\", \"logger\": \"UnhandledError\", \"reflector\": \"pkg/mod/k8s.io/client-go@v0.33.0/tools/cache/reflector.go:285\", \"type\": \"*v1alpha2.UDPRoute\", \"error\": \"apiserver not ready\"}",
    "detected_severity": "ERROR",
    "signature": "<TIMESTAMP>\tERROR\tprovider\tcache/reflector.go:<PORT>\tFailed to watch\t{\"runner\": \"provider\", \"logger\": \"UnhandledError\", \"reflector\": \"pkg/mod/k8s.io/client-go@v0.33.0/tools/cache/reflector.go:<PORT>\", \"type\": \"*v1alpha2.UDPRoute\", \"error\": \"apiserver not ready\"}",
    "signature_hash": "ce5a64a9",
    "source": "real",
    "root_cause": "apiserver_not_ready",
    "severity": "error",
    "component": "envoy_gateway",
    "summary": "Envoy Gateway cannot watch resources because API server is not ready",
    "action_needed": "wait_for_apiserver"
  },
  {
    "timestamp": 1766958940716.0,
    "timestamp_human": "2025-12-28T15:55:40.716482",
    "namespace": "envoy-gateway-system",
    "pod": "envoy-gateway-775d8bf958-ldd5t",
    "container": "envoy-gateway",
    "node": "node-1",
    "log_line": "2025-12-28T21:55:40.272Z\tERROR\tprovider\tcache/reflector.go:200\tFailed to watch\t{\"runner\": \"provider\", \"logger\": \"UnhandledError\", \"reflector\": \"pkg/mod/k8s.io/client-go@v0.33.0/tools/cache/reflector.go:285\", \"type\": \"*v1alpha1.BackendTrafficPolicy\", \"error\": \"apiserver not ready\"}",
    "detected_severity": "ERROR",
    "signature": "<TIMESTAMP>\tERROR\tprovider\tcache/reflector.go:<PORT>\tFailed to watch\t{\"runner\": \"provider\", \"logger\": \"UnhandledError\", \"reflector\": \"pkg/mod/k8s.io/client-go@v0.33.0/tools/cache/reflector.go:<PORT>\", \"type\": \"*v1alpha1.BackendTrafficPolicy\", \"error\": \"apiserver not ready\"}",
    "signature_hash": "f966c5e2",
    "source": "real",
    "root_cause": "apiserver_not_ready",
    "severity": "error",
    "component": "envoy_gateway",
    "summary": "Envoy Gateway cannot watch BackendTrafficPolicy because API server is not ready",
    "action_needed": "wait_for_apiserver"
  },
  {
    "timestamp": 1766958940716.0,
    "timestamp_human": "2025-12-28T15:55:40.716480",
    "namespace": "envoy-gateway-system",
    "pod": "envoy-gateway-775d8bf958-ldd5t",
    "container": "envoy-gateway",
    "node": "node-1",
    "log_line": "2025-12-28T21:55:40.177Z\tERROR\tprovider\tcache/reflector.go:200\tFailed to watch\t{\"runner\": \"provider\", \"logger\": \"UnhandledError\", \"reflector\": \"pkg/mod/k8s.io/client-go@v0.33.0/tools/cache/reflector.go:285\", \"type\": \"*v1alpha1.HTTPRouteFilter\", \"error\": \"apiserver not ready\"}",
    "detected_severity": "ERROR",
    "signature": "<TIMESTAMP>\tERROR\tprovider\tcache/reflector.go:<PORT>\tFailed to watch\t{\"runner\": \"provider\", \"logger\": \"UnhandledError\", \"reflector\": \"pkg/mod/k8s.io/client-go@v0.33.0/tools/cache/reflector.go:<PORT>\", \"type\": \"*v1alpha1.HTTPRouteFilter\", \"error\": \"apiserver not ready\"}",
    "signature_hash": "ddeaaa9b",
    "source": "real",
    "root_cause": "apiserver_not_ready",
    "severity": "error",
    "component": "envoy_gateway",
    "summary": "Envoy Gateway cannot watch resources because API server is not ready",
    "action_needed": "wait_for_apiserver"
  },
  {
    "timestamp": 1766958940716.0,
    "timestamp_human": "2025-12-28T15:55:40.716479",
    "namespace": "envoy-gateway-system",
    "pod": "envoy-gateway-775d8bf958-ldd5t",
    "container": "envoy-gateway",
    "node": "node-1",
    "log_line": "2025-12-28T21:55:40.145Z\tERROR\tprovider\tcache/reflector.go:200\tFailed to watch\t{\"runner\": \"provider\", \"logger\": \"UnhandledError\", \"reflector\": \"pkg/mod/k8s.io/client-go@v0.33.0/tools/cache/reflector.go:285\", \"type\": \"*v1alpha2.TLSRoute\", \"error\": \"apiserver not ready\"}",
    "detected_severity": "ERROR",
    "signature": "<TIMESTAMP>\tERROR\tprovider\tcache/reflector.go:<PORT>\tFailed to watch\t{\"runner\": \"provider\", \"logger\": \"UnhandledError\", \"reflector\": \"pkg/mod/k8s.io/client-go@v0.33.0/tools/cache/reflector.go:<PORT>\", \"type\": \"*v1alpha2.TLSRoute\", \"error\": \"apiserver not ready\"}",
    "signature_hash": "5abf0e52",
    "source": "real",
    "root_cause": "apiserver_not_ready",
    "severity": "error",
    "component": "envoy_gateway",
    "summary": "Envoy Gateway cannot watch resources because API server is not ready",
    "action_needed": "wait_for_apiserver"
  },
  {
    "timestamp": 1766958940716.0,
    "timestamp_human": "2025-12-28T15:55:40.716477",
    "namespace": "envoy-gateway-system",
    "pod": "envoy-gateway-775d8bf958-ldd5t",
    "container": "envoy-gateway",
    "node": "node-1",
    "log_line": "2025-12-28T21:55:40.123Z\tERROR\tprovider\tcache/reflector.go:200\tFailed to watch\t{\"runner\": \"provider\", \"logger\": \"UnhandledError\", \"reflector\": \"pkg/mod/k8s.io/client-go@v0.33.0/tools/cache/reflector.go:285\", \"type\": \"*v1.GRPCRoute\", \"error\": \"apiserver not ready\"}",
    "detected_severity": "ERROR",
    "signature": "<TIMESTAMP>\tERROR\tprovider\tcache/reflector.go:<PORT>\tFailed to watch\t{\"runner\": \"provider\", \"logger\": \"UnhandledError\", \"reflector\": \"pkg/mod/k8s.io/client-go@v0.33.0/tools/cache/reflector.go:<PORT>\", \"type\": \"*v1.GRPCRoute\", \"error\": \"apiserver not ready\"}",
    "signature_hash": "e9b06a03",
    "source": "real",
    "root_cause": "apiserver_not_ready",
    "severity": "error",
    "component": "envoy_gateway",
    "summary": "Envoy Gateway cannot watch resources because API server is not ready",
    "action_needed": "wait_for_apiserver"
  }
]